{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "317ff0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "import torchio as tio\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a53f52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_split(data, idx):\n",
    "    return list(np.array(data)[idx])\n",
    "\n",
    "\n",
    "def load_data(path, files_pattern):\n",
    "    return sorted(glob.glob(os.path.join(path, files_pattern)))\n",
    "\n",
    "\n",
    "def get_kfold_splitter(nfolds):\n",
    "    return KFold(n_splits=nfolds, shuffle=True, random_state=12345)\n",
    "\n",
    "\n",
    "def get_test_fnames(args, data_path, meta=None):\n",
    "    kfold = get_kfold_splitter(args.nfolds)\n",
    "    test_imgs = load_data(data_path, \"*_x.npy\")\n",
    "    if args.exec_mode == \"predict\" and \"val\" in data_path:\n",
    "        _, val_idx = list(kfold.split(test_imgs))[args.fold]\n",
    "        test_imgs = sorted(get_split(test_imgs, val_idx))\n",
    "        if meta is not None:\n",
    "            meta = sorted(get_split(meta, val_idx))\n",
    "    return test_imgs, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "865a3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds=3\n",
    "data_path = '/data/private_data/schw/33_3d'\n",
    "kfold = KFold(n_splits=nfolds, shuffle=True, random_state=12345)\n",
    "fold=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5c31f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_data(data_path, \"*_meta.npy\")\n",
    "orig_lbl = load_data(data_path, \"*_orig_lbl.npy\")\n",
    "        \n",
    "imgs, lbls = load_data(data_path, \"*_x.npy\"), load_data(data_path, \"*_y.npy\")\n",
    "train_idx, val_idx = list(kfold.split(imgs))[fold]\n",
    "orig_lbl, meta = get_split(orig_lbl, val_idx), get_split(meta, val_idx)\n",
    "train_imgs, train_lbls = get_split(imgs, train_idx), get_split(lbls, train_idx)\n",
    "val_imgs_2, val_lbls_2 = get_split(imgs, val_idx), get_split(lbls, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44dd701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lbls_2 = [each.split('/')[-1].split('.')[0] for each in val_lbls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b640a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import mpu.io\n",
    "\n",
    "# data = {'fold_0': val_lbls_0,\n",
    "#         'fold_1': val_lbls_1,\n",
    "#         'fold_2': val_lbls_2,\n",
    "#        }\n",
    "# print(json.dumps(data, indent=4))\n",
    "\n",
    "\n",
    "# mpu.io.write('schw_seed.json', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "196610d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:35<00:00,  1.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:34<00:00,  1.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:35<00:00,  1.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:38<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data_anvar/public_datasets/preproc_study/gbm/3a_atlas'\n",
    "t1_paths = []\n",
    "t2_paths = []\n",
    "flair_paths = []\n",
    "t1c_paths = []\n",
    "for sub in train_imgs:\n",
    "    sub = sub.split('/')[-1][:-6]\n",
    "#     print(sub)\n",
    "    t1_paths.append(os.path.join(data_path, sub, 'T1.nii.gz'))\n",
    "    t2_paths.append(os.path.join(data_path, sub, 'T2.nii.gz'))\n",
    "    t1c_paths.append(os.path.join(data_path, sub, 'CT1.nii.gz'))\n",
    "    flair_paths.append(os.path.join(data_path, sub, 'FLAIR.nii.gz'))\n",
    "landmarks_t1_fold2 = tio.HistogramStandardization.train(\n",
    "    t1_paths,\n",
    "    output_path='/home/polina/DeepLearningExamples/PyTorch/Segmentation/nnUNet/notebooks/t1_landmarks_fold2.npy',\n",
    ")\n",
    "landmarks_t2_fold2 = tio.HistogramStandardization.train(\n",
    "    t2_paths,\n",
    "    output_path='/home/polina/DeepLearningExamples/PyTorch/Segmentation/nnUNet/notebooks/t2_landmarks_fold2.npy',\n",
    ")\n",
    "landmarks_t1c_fold2 = tio.HistogramStandardization.train(\n",
    "    t1c_paths,\n",
    "    output_path='/home/polina/DeepLearningExamples/PyTorch/Segmentation/nnUNet/notebooks/t1c_landmarks_fold2.npy',\n",
    ")\n",
    "landmarks_flair_fold2 = tio.HistogramStandardization.train(\n",
    "    flair_paths,\n",
    "    output_path='/home/polina/DeepLearningExamples/PyTorch/Segmentation/nnUNet/notebooks/flair_landmarks_fold2.npy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fc9396d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_dict = {'t1': landmarks_t1_fold2,\n",
    "                  't2': landmarks_t2_fold2,\n",
    "                  't1c': landmarks_t1c_fold2,\n",
    "                  'flair': landmarks_flair_fold2}\n",
    "histogram_transform = tio.HistogramStandardization(landmarks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d0031492",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "for sub in train_imgs:\n",
    "    sub = sub.split('/')[-1][:-6]\n",
    "    subject = tio.Subject(\n",
    "        t1=tio.ScalarImage(os.path.join(data_path, sub, 'T1.nii.gz')),\n",
    "        t2=tio.ScalarImage(os.path.join(data_path, sub, 'T2.nii.gz')),\n",
    "        t1c=tio.ScalarImage(os.path.join(data_path, sub, 'CT1.nii.gz')),\n",
    "        flair=tio.ScalarImage(os.path.join(data_path, sub, 'FLAIR.nii.gz')),\n",
    "        label=tio.LabelMap(os.path.join(data_path, sub, 'CT1_SEG.nii.gz')),\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "dataset = tio.SubjectsDataset(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "990ab60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [12:26<00:00, 10.97s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_path = '/data/private_data/6_histogram_fold2'\n",
    "for i ,sample in enumerate(tqdm(dataset)):\n",
    "        transformed = histogram_transform(sample)\n",
    "        if not os.path.exists(os.path.join(out_path,str(transformed.t1.path).split('/')[-2])):\n",
    "            os.mkdir(os.path.join(out_path,str(transformed.t1.path).split('/')[-2]))\n",
    "        transformed.t1.save(os.path.join(out_path,str(transformed.t1.path).split('/')[-2], 'T1.nii.gz'))\n",
    "        transformed.t2.save(os.path.join(out_path,str(transformed.t2.path).split('/')[-2], 'T2.nii.gz'))\n",
    "        transformed.t1c.save(os.path.join(out_path,str(transformed.t1c.path).split('/')[-2], 'CT1.nii.gz'))\n",
    "        transformed.flair.save(os.path.join(out_path,str(transformed.flair.path).split('/')[-2], 'FLAIR.nii.gz'))\n",
    "        transformed.label.save(os.path.join(out_path,str(transformed.label.path).split('/')[-2], 'CT1_SEG.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c223c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/data/private_data/6_histogram_fold2'\n",
    "data_path = '/data_anvar/public_datasets/preproc_study/gbm/3a_atlas'\n",
    "for each in val_imgs:\n",
    "    sub = each.split('/')[-1][:-6]\n",
    "    print(sub)\n",
    "    sub_in = os.path.join(data_path,sub)\n",
    "    sub_out = os.path.join(out_path,sub)\n",
    "    if not os.path.exists(sub_out):\n",
    "            os.system(f'cp -r {sub_in} {sub_out}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7076679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from glob2 import glob\n",
    "from subprocess import call\n",
    "import time\n",
    "\n",
    "import nibabel\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def load_nifty(directory, example_id, suffix):\n",
    "    return nibabel.load(f'{directory}/{suffix}.nii.gz')\n",
    "\n",
    "\n",
    "def load_channels(d, example_id):\n",
    "    return [load_nifty(d, example_id, suffix) for suffix in [\"FLAIR\", \"T1\", \"CT1\", \"T2\"]]\n",
    "\n",
    "\n",
    "def get_data(nifty, dtype=\"int16\"):\n",
    "    if dtype == \"int16\":\n",
    "        data = np.abs(nifty.get_fdata().astype(np.int16))\n",
    "        data[data == -32768] = 0\n",
    "        return data\n",
    "    return nifty.get_fdata().astype(np.uint8)\n",
    "\n",
    "\n",
    "def prepare_nifty(d, d_out):\n",
    "    sub = d.split(\"/\")[-1]\n",
    "    flair, t1, t1ce, t2 = load_channels(d, sub)\n",
    "    affine, header = flair.affine, flair.header\n",
    "    vol = np.stack([get_data(flair), get_data(t1), get_data(t1ce), get_data(t2)], axis=-1)\n",
    "    vol = nibabel.nifti1.Nifti1Image(vol, affine, header=header)\n",
    "#     print('l')\n",
    "#     print( os.path.join(d_out, sub + \".nii.gz\"))\n",
    "    nibabel.save(vol, os.path.join(d_out, sub + \".nii.gz\"))\n",
    "#     print(glob(f'{d}/{sub}/**/MASK.nii.gz')[0])\n",
    "    if os.path.exists(f'{d}/CT1_SEG.nii.gz'):\n",
    "        seg = load_nifty(d, sub, \"CT1_SEG\")\n",
    "        affine, header = seg.affine, seg.header\n",
    "        vol = get_data(seg, \"unit8\")\n",
    "#         vol[vol == 4] = 3\n",
    "#         mask = np.zeros(vol.shape, dtype=np.uint8)\n",
    "#         mask[vol == 2] = 1\n",
    "#         mask[vol == 3] = 2\n",
    "#         mask[vol == 1] = 3\n",
    "        seg = nibabel.nifti1.Nifti1Image(vol, affine, header=header)\n",
    "#         print(os.path.join(d_out, sub + \"_seg.nii.gz\"))\n",
    "        nibabel.save(seg, os.path.join(d_out, sub + \"_seg.nii.gz\"))\n",
    "\n",
    "\n",
    "def prepare_dirs(d_out, train):\n",
    "    img_path, lbl_path = os.path.join(d_out, \"images\"), os.path.join(d_out, \"labels\")\n",
    "    call(f\"mkdir {img_path}\", shell=True)\n",
    "    if train:\n",
    "        call(f\"mkdir {lbl_path}\", shell=True)\n",
    "    dirs = glob(os.path.join(d_out, \"*\"))\n",
    "    for d in dirs:\n",
    "        if '.nii.gz' in d:\n",
    "                if \"FLAIR\" in d or \"T1\" in d or \"CT1\" in d or \"T2\" in d:\n",
    "                    continue\n",
    "                if \"_seg\" in d:\n",
    "                    call(f\"mv {d} {lbl_path}\", shell=True)\n",
    "                else:\n",
    "                    call(f\"mv {d} {img_path}\", shell=True)\n",
    "                \n",
    "#         call(f\"rm -rf {d}\", shell=True)\n",
    "         \n",
    "\n",
    "def prepare_dataset_json(d_out, train):\n",
    "    images, labels = glob(os.path.join(d_out, \"images\", \"*\")), glob(os.path.join(d_out, \"labels\", \"*\"))\n",
    "    images = sorted([img.replace(d_out + \"/\", \"\") for img in images])\n",
    "    labels = sorted([lbl.replace(d_out + \"/\", \"\") for lbl in labels])\n",
    "    \n",
    "    modality = {\"0\": \"FLAIR\", \"1\": \"T1\", \"2\": \"T1CE\", \"3\": \"T2\"}\n",
    "    labels_dict = {\"0\": \"background\", \"1\": \"edema\", \"2\": \"tumor core\", \"3\": \"enhancing tumour\"}\n",
    "    if train:\n",
    "        key = \"training\"\n",
    "        data_pairs = [{\"image\": img, \"label\": lbl} for (img, lbl) in zip(images, labels)]\n",
    "    else:\n",
    "        key = \"test\"\n",
    "        data_pairs = [{\"image\": img} for img in images]\n",
    "\n",
    "    dataset = {\n",
    "        \"labels\": labels_dict,\n",
    "        \"modality\": modality,\n",
    "        key: data_pairs,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(d_out, \"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(dataset, outfile)\n",
    "\n",
    "\n",
    "def run_parallel(func, args):\n",
    "    return Parallel(n_jobs=os.cpu_count())(delayed(func)(arg) for arg in args)\n",
    "\n",
    "\n",
    "def prepare_dataset(data, train, out):\n",
    "    print(f\"Preparing GBM dataset from: {data}\")\n",
    "    d_out = out\n",
    "    if not os.path.exists(d_out):\n",
    "        call(f\"mkdir {d_out}\", shell=True)\n",
    "    start = time.time()\n",
    "#     run_parallel(prepare_nifty, sorted(glob(os.path.join(data, \"*\"))))\n",
    "    for each in sorted(glob(os.path.join(data, \"*\"))):\n",
    "        if os.path.exists(os.path.join(each, \"CT1_SEG.nii.gz\")):\n",
    "            prepare_nifty(each, d_out)\n",
    "    prepare_dirs(d_out, train)\n",
    "    prepare_dataset_json(d_out, train)\n",
    "    end = time.time()\n",
    "    print(f\"Preparing time: {(end - start):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c09eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing GBM dataset from: /data_anvar/public_datasets/preproc_study/gbm/6_hist/6_hist_fold_1\n",
      "Preparing time: 365.88\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset('/data_anvar/public_datasets/preproc_study/gbm/6_hist/6_hist_fold_1',True, '/data/private_data/6_histogram_fold_1' )\n",
    "# prepare_dataset('/data_anvar/public_datasets/preproc_study/gbm/7a_resamp',True, '/data/private_data/7a_resample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "790e1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT1.nii.gz  CT1_SEG.nii.gz  FLAIR.nii.gz  T1.nii.gz  T2.nii.gz\n"
     ]
    }
   ],
   "source": [
    "!cd /data_anvar/public_datasets/preproc_study/gbm/6_hist/6_hist_fold_1/TCGA-02-0006 && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35749ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing /data/private_data/6_histogram_fold_1\n",
      "Pre-processing time: 72.37\n"
     ]
    }
   ],
   "source": [
    "!python3 ../preprocess.py --data /data/private_data --task 31.1 --ohe --exec_mode training --results /data/private_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b9779be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/data_anvar/public_datasets/preproc_study/gbm/6_hist/6_hist_fold_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "262f5463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/data/private_data/31.0_3d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a4b173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/data/private_data/31.1_3d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9a63948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd /data/private_data/31.2_3d/ && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "66f68e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5363204\n",
      "-rw-r--r-- 1 root root 610204723 Mar  1 12:12 'best_epoch=0-dice_mean=6.54.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:54 'best_epoch=27-dice_mean=57.69.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:37 'epoch=14-dice_mean=53.15.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:44 'epoch=19-dice_mean=54.09.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:51 'epoch=24-dice_mean=55.33.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:57 'epoch=29-dice_mean=57.60.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:20 'epoch=4-dice_mean=34.75.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 12:30 'epoch=9-dice_mean=44.89.ckpt'\n",
      "-rw-r--r-- 1 root root 610206063 Mar  1 13:01  last.ckpt\n"
     ]
    }
   ],
   "source": [
    "!cd /results/gbm_results/6_histogram_fold_1/fold-1/checkpoints && ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0c1973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/data_anvar/public_datasets/preproc_study/gbm/6_hist/6_histogram/6_hist_fold_0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e19e4005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "ch = torch.load('/results/gbm_results/6_histogram_fold_1/fold-1/checkpoints/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c5a0d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "global_step\n",
      "pytorch-lightning_version\n",
      "state_dict\n",
      "callbacks\n",
      "optimizer_states\n",
      "lr_schedulers\n",
      "native_amp_scaling_state\n",
      "hparams_name\n",
      "hyper_parameters\n"
     ]
    }
   ],
   "source": [
    "for i in ch:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71434b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d485ba74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': Namespace(affinity='socket_unique_contiguous', amp=True, batch_size=2, benchmark=False, blend='gaussian', brats=True, ckpt_path=None, data='/data/private_data/31.1_3d', data2d_dim=3, deep_supervision=True, deep_supr_num=2, depth=6, dim=3, epochs=100, exec_mode='train', filters=[64, 96, 128, 192, 256, 384, 512], focal=False, fold=1, gpus=1, gradient_clip_val=0, invert_resampled_y=False, learning_rate=0.0003, logname=None, min_fmap=2, momentum=0.99, more_chn=False, negative_slope=0.01, nfolds=3, no_back_in_output=False, norm='instance', num_workers=8, nvol=4, optimizer='adam', overlap=0.5, oversampling=0.4, patience=100, profile=False, res_block=False, results='/results/gbm_results/6_histogram_fold_1/fold-1', resume_training=False, save_ckpt=True, save_preds=False, scheduler=True, seed=1, skip_first_n_eval=0, sync_batchnorm=False, task='31.1', test_batches=0, train_batches=0, tta=False, val_batch_size=4, warmup=5, weight_decay=0.0001),\n",
       " 'triton': False,\n",
       " 'data_dir': None}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch['hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29a43736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "0 training, 0 validation, 102 test examples\n",
      "Filters: [64, 96, 128, 192, 256, 384, 512],\n",
      "Kernels: [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
      "Strides: [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:45: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:906: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "Testing:   7%|██▏                             | 7/102 [06:12<1:24:44, 53.52s/it]^C\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1 && python ../main.py --exec_mode predict --brats --task 31.1_3d --data /data/private_data/31.1_3d --dim 3 --fold 1 --nfolds 3 --ckpt_path /results/gbm_results/6_histogram_fold_1/fold-1/checkpoints/best_epoch=81-dice_mean=61.77.ckpt --results /results/gbm_infer/6_histogram_fold_1 --amp --tta --save_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56987622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20_3d  31.0_3d\t 6_histogram_fold_0  gbm_2a_interp\n",
      "22_3d  31.1_3d\t 6_histogram_fold_1  gbm_3a_atlas_train\n",
      "27_3d  34_3d\t 6_histogram_fold_2  schw\n",
      "2b_n4  3a_susan  bgpd_1_reg\t     self_supervision\n"
     ]
    }
   ],
   "source": [
    "!cd /data/private_data && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3ec6443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing /data/private_data/6_histogram_fold_0\n",
      "Pre-processing time: 71.26\n"
     ]
    }
   ],
   "source": [
    "!python3 ../preprocess.py --data /data/private_data/ --task 31.0 --ohe --exec_mode training --results /data/private_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044360a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
