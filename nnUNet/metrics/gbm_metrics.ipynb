{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826ef831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib    \n",
    "from pathlib import Path\n",
    "from surface_distance import metrics\n",
    "from tqdm import tqdm\n",
    "import ants\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c726158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_invert_resample_1cl(data, path_to_orig, path_to_resampled):\n",
    "    # path_to_pred = *npz, path_to_orig = *1_reg, path_to_resampled = *4a_resample\n",
    "    # *.npz archives sometimes can be recognised wrong, if extracted and saved back at the same time\n",
    "#     data = np.load(path_to_pred, allow_pickle=True)['arr_0']\n",
    "        data = data.transpose(0,3,2,1).astype('float32')\n",
    "        old_orig = ants.image_read(path_to_resampled)\n",
    "        new_orig = ants.image_read(path_to_orig)\n",
    "        old_like = old_orig.new_image_like(data[0])\n",
    "        new_img = ants.resample_image(old_like, new_orig.spacing, False, 0)\n",
    "        output_file = new_img.numpy().astype('float16')\n",
    "        if new_orig.shape[0]-output_file.shape[0] < 0:\n",
    "            output_file = output_file[:new_orig.shape[0], :new_orig.shape[1],:new_orig.shape[2] ]\n",
    "        elif new_orig.shape[0]-output_file.shape[0] > 0:\n",
    "            output_file = np.pad(output_file, ((0, new_orig.shape[0]-output_file.shape[0]), (0, new_orig.shape[1]-output_file.shape[1]), (0, new_orig.shape[2]-output_file.shape[2])), 'constant', constant_values=0)\n",
    "\n",
    "        return (output_file)\n",
    "    \n",
    "def pred_invert_resample_classes(data, mat_file_path, path_to_orig, path_to_resampled, mod):\n",
    "\n",
    "        data = data.transpose(0,3,2,1).astype('float32')\n",
    "        old_orig_ct1 = ants.image_read(path_to_resampled)\n",
    "        new_orig_ct1 = ants.image_read(path_to_orig)\n",
    "    \n",
    "        old_like_ch_0 = old_orig_ct1.new_image_like(data[0])\n",
    "        old_like_ch_1 = old_orig_ct1.new_image_like(data[1])\n",
    "        old_like_ch_2 = old_orig_ct1.new_image_like(data[2])\n",
    "        if mod == '2a_interp':\n",
    "            new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.shape, True, 0)\n",
    "            new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.shape, True, 0)\n",
    "            new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.shape, True, 0)\n",
    "        if mod == '3a_atlas':\n",
    "            new_img_0 = ants.apply_transforms(new_orig_ct1, old_like_ch_0, whichtoinvert=[True],\n",
    "                                          transformlist = mat_file_path)\n",
    "            new_img_1 = ants.apply_transforms(new_orig_ct1, old_like_ch_1, whichtoinvert=[True],\n",
    "                                          transformlist = mat_file_path)\n",
    "            new_img_2 = ants.apply_transforms(new_orig_ct1, old_like_ch_2, whichtoinvert=[True],\n",
    "                                          transformlist = mat_file_path)\n",
    "        else:\n",
    "            new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.spacing, False, 0)\n",
    "            new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.spacing, False, 0)\n",
    "            new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.spacing, False, 0)\n",
    "       \n",
    "        new_img_shape =  new_img_2.numpy().shape\n",
    "\n",
    "        new_array = np.zeros(tuple([3] + list(new_img_shape)), dtype='float16')\n",
    "        new_array[0] = new_img_0.numpy()\n",
    "        new_array[1] = new_img_1.numpy()\n",
    "        new_array[2] = new_img_2.numpy()\n",
    "        output_file = new_array.astype('float16')\n",
    "        if (new_orig_ct1.shape[2]-output_file.shape[3] < 0 ) or (new_orig_ct1.shape[1]-output_file.shape[2] < 0) or (new_orig_ct1.shape[0]-output_file.shape[1] < 0):\n",
    "            print(1)\n",
    "            output_file = output_file[:, :new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "            \n",
    "        if (new_orig_ct1.shape[2]-output_file.shape[3] > 0) or (new_orig_ct1.shape[1]-output_file.shape[2] > 0 ) or (new_orig_ct1.shape[0]-output_file.shape[1] > 0):\n",
    "            print(2)\n",
    "            output_file = np.pad(output_file, ((0,0), (0, new_orig_ct1.shape[0]-output_file.shape[1]), (0, new_orig_ct1.shape[1]-output_file.shape[2]), (0, new_orig_ct1.shape[2]-output_file.shape[3])), 'constant', constant_values=0)\n",
    "\n",
    "        output_file = output_file[:,:new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "\n",
    "        return (output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e32a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_and_specificity(mask_gt, mask_pred):\n",
    "    \"\"\" Computes sensitivity and specificity\n",
    "     sensitivity  = TP/(TP+FN)\n",
    "     specificity  = TN/(TN+FP) \"\"\"\n",
    "    volume_sum = mask_gt.sum() + mask_pred.sum()\n",
    "    tp = (mask_gt & mask_pred).sum()\n",
    "    tn = (~mask_gt & ~mask_pred).sum()\n",
    "    fp = (~mask_gt & mask_pred).sum()\n",
    "    fn = (mask_gt & ~mask_pred).sum()\n",
    "#     TP/(TP+FP) - precision; TP/(TP+FN) - recall\n",
    "    return tp/(tp+fn), tp/(tp+fp), tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6bbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_brats_1cl(true_mask, pred_mask, ids, spaces):\n",
    "    \"\"\" Takes two file locations as input and validates surface distances.\n",
    "    Be careful with dimensions of saved `pred` it should be 3D.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _columns = ['Ids','Dice_1'\n",
    "                'Hausdorff95_1',\n",
    "                'Sensitivity_1',\n",
    "               'Specificity_1',\n",
    "               'Surface_dice_1',\n",
    "               'Precision_1']\n",
    "    \n",
    "    df = pd.DataFrame(columns = _columns)\n",
    "    df.at[0,'Ids'] = ids\n",
    "    #class 1\n",
    "    distances = metrics.compute_surface_distances((true_mask==1), (pred_mask==1), spaces)\n",
    "    df.at[0,'Dice_1'] = metrics.compute_dice_coefficient((true_mask==1), (pred_mask==1))\n",
    "    df.at[0,'Surface_dice_1'] = metrics.compute_surface_dice_at_tolerance(distances,1)\n",
    "    df.at[0,'Hausdorff95_1'] = metrics.compute_robust_hausdorff(distances, 95)\n",
    "    sens, precision, spec = sensitivity_and_specificity((true_mask==1), (pred_mask==1))\n",
    "    df.at[0,'Sensitivity_1'] = sens\n",
    "    df.at[0,'Precision_1'] = precision\n",
    "    df.at[0,'Specificity_1'] = spec\n",
    "    return df\n",
    "\n",
    "def calculate_metrics_brats(true_mask, pred_mask, ids, spaces):\n",
    "    \"\"\" Takes two file locations as input and validates surface distances.\n",
    "    Be careful with dimensions of saved `pred` it should be 3D.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _columns = ['Ids','Dice_1', 'Dice_2', 'Dice_3',\n",
    "                'Hausdorff95_1', 'Hausdorff95_2', 'Hausdorff95_3',\n",
    "                'Sensitivity_1', 'Sensitivity_2', 'Sensitivity_3',\n",
    "               'Specificity_1', 'Specificity_2', 'Specificity_3',\n",
    "               'Surface_dice_1', 'Surface_dice_2', 'Surface_dice_3',\n",
    "               'Precision_1', 'Precision_2', 'Precision_3']\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns = _columns)\n",
    "    df.at[0,'Ids'] = ids\n",
    "    #class 1\n",
    "    distances = metrics.compute_surface_distances((true_mask[0,:,:,:]==1), (pred_mask[0,:,:,:]==1), spaces)\n",
    "    df.at[0,'Dice_1'] = metrics.compute_dice_coefficient((true_mask[0,:,:,:]==1), (pred_mask[0,:,:,:]==1))\n",
    "    df.at[0,'Surface_dice_1'] = metrics.compute_surface_dice_at_tolerance(distances,1)\n",
    "    df.at[0,'Hausdorff95_1'] = metrics.compute_robust_hausdorff(distances, 95)\n",
    "    sens, precision, spec = sensitivity_and_specificity((true_mask[0,:,:,:]==1), (pred_mask[0,:,:,:]==1))\n",
    "    df.at[0,'Sensitivity_1'] = sens\n",
    "    df.at[0,'Precision_1'] = precision\n",
    "    df.at[0,'Specificity_1'] = spec\n",
    "    #class 2\n",
    "    distances = metrics.compute_surface_distances((true_mask[1,:,:,:]==1), (pred_mask[1,:,:,:]==1), spaces)\n",
    "    df.at[0,'Dice_2'] = metrics.compute_dice_coefficient((true_mask[1,:,:,:]==1), (pred_mask[1,:,:,:]==1))\n",
    "    df.at[0,'Surface_dice_2'] = metrics.compute_surface_dice_at_tolerance(distances,1)\n",
    "    df.at[0,'Hausdorff95_2'] = metrics.compute_robust_hausdorff(distances, 95)\n",
    "    sens,precision, spec= sensitivity_and_specificity((true_mask[1,:,:,:]==1), (pred_mask[1,:,:,:]==1))\n",
    "    df.at[0,'Sensitivity_2'] = sens\n",
    "    df.at[0,'Precision_2'] = precision\n",
    "    df.at[0,'Specificity_2'] = spec\n",
    "    #class 3\n",
    "    distances = metrics.compute_surface_distances((true_mask[2,:,:,:]==1), (pred_mask[2,:,:,:]==1), spaces)\n",
    "    df.at[0,'Dice_3'] = metrics.compute_dice_coefficient((true_mask[2,:,:,:]==1), (pred_mask[2,:,:,:]==1))\n",
    "    df.at[0,'Surface_dice_3'] = metrics.compute_surface_dice_at_tolerance(distances,1)\n",
    "    df.at[0,'Hausdorff95_3'] = metrics.compute_robust_hausdorff(distances, 95)\n",
    "    sens, precision, spec= sensitivity_and_specificity((true_mask[2,:,:,:]==1), (pred_mask[2,:,:,:]==1))\n",
    "    df.at[0,'Sensitivity_3'] = sens\n",
    "    df.at[0,'Precision_3'] = precision\n",
    "    df.at[0,'Specificity_3'] = spec\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f83f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def calculate_metrics(subjects, path_to_file, path_to_orig, path_to_pred, path_to_resamp, path_to_target, dataset, out = '/home/polina/glioma/all_dice_metrics.csv', mod=None ):\n",
    "    \n",
    "    \"\"\" \n",
    "    - path_to_pred - path to folder with predict subjects\n",
    "    - path_to_target - path to folder with target subjects\n",
    "    - name_pred - name for prediction, ex -brainTumorMask_SRI.nii.gz\n",
    "    - name_target - name for targets, ex -GTV_to_SRI.nii.gz\n",
    "    - spaces - if false - [1,1,1]\n",
    "    - name_csv - name files for each subjects\n",
    "    - path_csv_all - path to the main file with metrics for each subjects\n",
    "    \"\"\"\n",
    "    _columns = ['Ids','Dice_1', 'Dice_2', 'Dice_3',\n",
    "                'Hausdorff95_1', 'Hausdorff95_2', 'Hausdorff95_3',\n",
    "                'Sensitivity_1', 'Sensitivity_2', 'Sensitivity_3',\n",
    "               'Specificity_1', 'Specificity_2', 'Specificity_3',\n",
    "               'Surface_dice_1', 'Surface_dice_2', 'Surface_dice_3',\n",
    "               'Precision_1', 'Precision_2', 'Precision_3']\n",
    "#     _columns = ['Ids','Dice_1'\n",
    "#                 'Hausdorff95_1',\n",
    "#                 'Sensitivity_1',\n",
    "#                'Specificity_1',\n",
    "#                'Surface_dice_1',\n",
    "#                'Precision_1']\n",
    "    \n",
    "    af_all = pd.DataFrame(columns = _columns)\n",
    "    pred_folder = Path(path_to_pred)\n",
    "    orig_folder = Path(path_to_orig)\n",
    "    resamp_folder = Path(path_to_resamp)\n",
    "    target_folder = Path(path_to_target)\n",
    "    file_folder = Path(path_to_file)\n",
    "    for ids in tqdm(subjects):\n",
    "        pred_sub = os.path.join(pred_folder, ids + '.npy.npz')\n",
    "        orig_sub = os.path.join(orig_folder, ids,'CT1_SEG.nii.gz')\n",
    "        resamp_sub = os.path.join(resamp_folder, ids,'CT1_SEG.nii.gz')\n",
    "        mat_fie_sub = os.path.join(file_folder, ids,'T1C_to_SRI_inv.mat')\n",
    "        targets = ants.image_read(f'{target_folder}/{ids}/CT1_SEG.nii.gz')\n",
    "        spaces = targets.spacing\n",
    "        targets = targets.numpy()\n",
    "        data = np.load(pred_sub, allow_pickle=True)['arr_0']\n",
    "\n",
    "        if np.shape(data)[0] == 1: \n",
    "            prediction = pred_invert_resample_1cl(data,mat_fie_sub, orig_sub, resamp_sub, mod)\n",
    "            prediction = np.round(prediction, 0)\n",
    "            df = calculate_metrics_brats_1cl(targets.astype('int'), prediction.astype('int'), ids, spaces)\n",
    "        elif np.shape(data)[0] > 1: \n",
    "            prediction = pred_invert_resample_classes(data, mat_fie_sub, orig_sub, resamp_sub, mod)\n",
    "            prediction = np.round(prediction, 0)\n",
    "            y_wt, y_tc, y_et = targets > 0, ((targets == 1) + (targets == 3)) > 0, targets == 3\n",
    "            targets = np.stack([y_wt, y_tc, y_et], axis=0).astype(int)\n",
    "            df=calculate_metrics_brats(targets.astype('int'), prediction.astype('int'), ids, spaces)\n",
    "\n",
    "        os.makedirs(os.path.join(out, dataset,ids), exist_ok = True)\n",
    "        out_path = os.path.join(out, dataset,ids, path_to_pred.split('/')[-2] + '_'+ path_to_pred.split('best_')[-1].replace('=', '_') + '.json')\n",
    "        sub_dict = {dataset : {path_to_pred.split('/')[-2]: {path_to_pred.split('_')[-2]: {}}}}\n",
    "        sub_dict[dataset][path_to_pred.split('/')[-2]][path_to_pred.split('_')[-2]] = df.to_dict('records')[0]\n",
    "        with open(out_path, 'w') as fp:\n",
    "            json.dump(sub_dict, fp)\n",
    "        af_all = af_all.append(df)  \n",
    "    print(af_all.mean())\n",
    "    print(len(af_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b3c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_folder = 'path_to/gbm/orig'\n",
    "resample_folder = 'path_to/gbm/4a_resamp'\n",
    "file = '/path_to_mat_file_folder/3a_atlas' # mat file for 3a_atlas experiments\n",
    "pred_folder = 'path_to_pred/predictions_best_epoch=-dice_mean=_task=28_fold=2_tta'\n",
    "target_folder = '/path_to/gbm/1_reg'\n",
    "reg_1 = '/path_to/gbm/1_reg'\n",
    "out_json = '/results/metrics'\n",
    "dataset = 'gbm'\n",
    "subjects = [each[:-8] for each in os.listdir(pred_folder)]\n",
    "assert(len(subjects) == 102)\n",
    "calculate_metrics(subjects, file, reg_1, pred_folder, resample_folder, target_folder, dataset, out = out_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json = '/results/metrics/gbm/'\n",
    "dataset = 'gbm'\n",
    "task = 'gbm_4a_resamp_aug'\n",
    "fold = 'fold_2'\n",
    "_columns = ['Ids','Dice_1', 'Dice_2', 'Dice_3',\n",
    "                'Hausdorff95_1', 'Hausdorff95_2', 'Hausdorff95_3',\n",
    "                'Sensitivity_1', 'Sensitivity_2', 'Sensitivity_3',\n",
    "               'Specificity_1', 'Specificity_2', 'Specificity_3',\n",
    "               'Surface_dice_1', 'Surface_dice_2', 'Surface_dice_3',\n",
    "               'Precision_1', 'Precision_2', 'Precision_3']\n",
    "metrics_all = pd.DataFrame(columns = _columns)\n",
    "for i,sub in tqdm((enumerate(os.listdir(out_json)))):\n",
    "    for sub_t in os.listdir(os.path.join(out_json, sub)):\n",
    "        if f'{task}_epoch' in sub_t:\n",
    "            if fold in sub_t:\n",
    "                metrics = json.load(open(os.path.join(out_json, sub, sub_t)))\n",
    "                metrics = metrics[dataset][task][fold.replace('_', '=')]\n",
    "                for each in _columns:\n",
    "                    metrics_all.at[i,'Ids'] = sub\n",
    "                    if each != 'Ids':\n",
    "                        metrics_all.at[i,each] = np.round(metrics[each],3)\n",
    "                    \n",
    "print(len(metrics_all))\n",
    "print(metrics_all.mean())\n",
    "print(metrics_all.std())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
