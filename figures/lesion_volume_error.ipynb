{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e58e1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "# import torch\n",
    "import pandas as pd\n",
    "import nibabel as nib    \n",
    "from pathlib import Path\n",
    "from surface_distance import metrics\n",
    "from tqdm import tqdm\n",
    "# import torch.nn as nn\n",
    "import ants\n",
    "import json\n",
    "import ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14d1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_invert_resample(path_to_pred, path_to_orig, path_to_resampled):\n",
    "    # path_to_pred = *npz, path_to_orig = *1_reg, path_to_resampled = *4a_resample\n",
    "    # *.npz archives sometimes can be recognised wrong, if extracted and saved back at the same time\n",
    "#     data = np.load(path_to_pred, allow_pickle=True)['arr_0']\n",
    "    # schw\n",
    "    if np.shape(data)[0] == 1:\n",
    "        data = data.transpose(0,3,2,1).astype('float32')\n",
    "        old_orig = ants.image_read(path_to_resampled)\n",
    "        new_orig = ants.image_read(path_to_orig)\n",
    "        old_like = old_orig.new_image_like(data[0])\n",
    "        new_img = ants.resample_image(old_like, new_orig.spacing, False, 0)\n",
    "        output_file = new_img.numpy().astype('float16')\n",
    "    \n",
    "    # gbm and lgg\n",
    "    elif np.shape(data)[0] > 1:\n",
    "        data = data.transpose(0,3,2,1).astype('float32')\n",
    "\n",
    "        old_orig_ct1 = ants.image_read(path_to_resampled)\n",
    "        new_orig_ct1 = ants.image_read(path_to_orig)\n",
    "\n",
    "        old_like_ch_0 = old_orig_ct1.new_image_like(data[0])\n",
    "        old_like_ch_1 = old_orig_ct1.new_image_like(data[1])\n",
    "        old_like_ch_2 = old_orig_ct1.new_image_like(data[2])\n",
    "\n",
    "        new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1, False, 0)\n",
    "        new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1, False, 0)\n",
    "        new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1, False, 0)\n",
    "\n",
    "        new_img_shape =  new_img_2.numpy().shape\n",
    "\n",
    "        new_array = np.zeros(tuple([3] + list(new_img_shape)), dtype='float16')\n",
    "        new_array[0] = new_img_0.numpy()\n",
    "        new_array[1] = new_img_1.numpy()\n",
    "        new_array[2] = new_img_2.numpy()\n",
    "        output_file = new_array.transpose(0,3,2,1).astype('float16')\n",
    "    return (output_file)\n",
    "\n",
    "def pred_invert_resample_1cl(data, path_to_orig, path_to_resampled, resamp_sub, mod):\n",
    "    # path_to_pred = *npz, path_to_orig = *1_reg, path_to_resampled = *4a_resample\n",
    "    # *.npz archives sometimes can be recognised wrong, if extracted and saved back at the same time\n",
    "#     data = np.load(path_to_pred, allow_pickle=True)['arr_0']\n",
    "    # schw\n",
    "        data = data.transpose(0,3,2,1).astype('float32')\n",
    "        old_orig = ants.image_read(path_to_resampled)\n",
    "        new_orig = ants.image_read(path_to_orig)\n",
    "        old_like = old_orig.new_image_like(data[0])\n",
    "        new_img = ants.resample_image(old_like, new_orig.spacing, False, 0)\n",
    "        output_file = new_img.numpy().astype('float16')\n",
    "        if new_orig.shape[0]-output_file.shape[0] < 0:\n",
    "            output_file = output_file[:new_orig.shape[0], :new_orig.shape[1],:new_orig.shape[2] ]\n",
    "        elif new_orig.shape[0]-output_file.shape[0] > 0:\n",
    "            output_file = np.pad(output_file, ((0, new_orig.shape[0]-output_file.shape[0]), (0, new_orig.shape[1]-output_file.shape[1]), (0, new_orig.shape[2]-output_file.shape[2])), 'constant', constant_values=0)\n",
    "\n",
    "        return (output_file)\n",
    "    \n",
    "def pred_invert_resample_classes(data, mat_file_path, path_to_orig, path_to_resampled, mod):\n",
    "\n",
    "    # gbm and lgg\n",
    "        data = data.transpose(0,3,2,1).astype('float32')\n",
    "#         print(data.shape)\n",
    "        old_orig_ct1 = ants.image_read(path_to_resampled)\n",
    "        new_orig_ct1 = ants.image_read(path_to_orig)\n",
    "    \n",
    "#         print(old_orig_ct1.shape)\n",
    "#         print(new_orig_ct1.shape)\n",
    "        old_like_ch_0 = old_orig_ct1.new_image_like(data[0])\n",
    "        old_like_ch_1 = old_orig_ct1.new_image_like(data[1])\n",
    "        old_like_ch_2 = old_orig_ct1.new_image_like(data[2])\n",
    "#         print('old_like')\n",
    "# #         print(old_like_ch_2.shape)\n",
    "        if mod == '2a_interp':\n",
    "            new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.shape, True, 0)\n",
    "            new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.shape, True, 0)\n",
    "            new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.shape, True, 0)\n",
    "        if mod == '3a_atlas':\n",
    "            new_img_0 = ants.apply_transforms(new_orig_ct1, old_like_ch_0, whichtoinvert=[True],\n",
    "                                          transformlist = mat_file_path)\n",
    "            new_img_1 = ants.apply_transforms(new_orig_ct1, old_like_ch_1, whichtoinvert=[True],\n",
    "                                          transformlist = mat_file_path)\n",
    "            new_img_2 = ants.apply_transforms(new_orig_ct1, old_like_ch_2, whichtoinvert=[True],\n",
    "                                          transformlist = mat_file_path)\n",
    "        else:\n",
    "            new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.spacing, False, 0)\n",
    "            new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.spacing, False, 0)\n",
    "            new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.spacing, False, 0)\n",
    "       \n",
    "        new_img_shape =  new_img_2.numpy().shape\n",
    "\n",
    "        new_array = np.zeros(tuple([3] + list(new_img_shape)), dtype='float16')\n",
    "        new_array[0] = new_img_0.numpy()\n",
    "        new_array[1] = new_img_1.numpy()\n",
    "        new_array[2] = new_img_2.numpy()\n",
    "        output_file = new_array.astype('float16')\n",
    "#         print(output_file.shape)\n",
    "#         print('check_shape')\n",
    "#         print(new_orig_ct1.shape)\n",
    "#         print(new_orig_ct1.shape[2]-output_file.shape[3])\n",
    "#         print((new_orig_ct1.shape[1]-output_file.shape[2]))\n",
    "#         print((new_orig_ct1.shape[0]-output_file.shape[1]))\n",
    "        if (new_orig_ct1.shape[2]-output_file.shape[3] < 0 ) or (new_orig_ct1.shape[1]-output_file.shape[2] < 0) or (new_orig_ct1.shape[0]-output_file.shape[1] < 0):\n",
    "            print(1)\n",
    "            output_file = output_file[:, :new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "            \n",
    "        if (new_orig_ct1.shape[2]-output_file.shape[3] > 0) or (new_orig_ct1.shape[1]-output_file.shape[2] > 0 ) or (new_orig_ct1.shape[0]-output_file.shape[1] > 0):\n",
    "            print(2)\n",
    "            output_file = np.pad(output_file, ((0,0), (0, new_orig_ct1.shape[0]-output_file.shape[1]), (0, new_orig_ct1.shape[1]-output_file.shape[2]), (0, new_orig_ct1.shape[2]-output_file.shape[3])), 'constant', constant_values=0)\n",
    "\n",
    "        output_file = output_file[:,:new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "#         print(output_file.shape)\n",
    "        \n",
    "        return (output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f70258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(subjects, path_to_file, path_to_orig, path_to_pred, path_to_resamp, path_to_target, dataset, out = '/home/polina/glioma/all_dice_metrics.csv', mod=None ):\n",
    "    \n",
    "    \"\"\" \n",
    "    - path_to_pred - path to folder with predict subjects\n",
    "    - path_to_target - path to folder with target subjects\n",
    "    - name_pred - name for prediction, ex -brainTumorMask_SRI.nii.gz\n",
    "    - name_target - name for targets, ex -GTV_to_SRI.nii.gz\n",
    "    - spaces - if false - [1,1,1]\n",
    "    - name_csv - name files for each subjects\n",
    "    - path_csv_all - path to the main file with metrics for each subjects\n",
    "    \"\"\"\n",
    "    _columns = ['Ids','Dice_1', 'Dice_2', 'Dice_3',\n",
    "                'Hausdorff95_1', 'Hausdorff95_2', 'Hausdorff95_3',\n",
    "                'Sensitivity_1', 'Sensitivity_2', 'Sensitivity_3',\n",
    "               'Specificity_1', 'Specificity_2', 'Specificity_3',\n",
    "               'Surface_dice_1', 'Surface_dice_2', 'Surface_dice_3',\n",
    "               'Precision_1', 'Precision_2', 'Precision_3']\n",
    "#     _columns = ['Ids','Dice_1'\n",
    "#                 'Hausdorff95_1',\n",
    "#                 'Sensitivity_1',\n",
    "#                'Specificity_1',\n",
    "#                'Surface_dice_1',\n",
    "#                'Precision_1']\n",
    "    \n",
    "    af_all = pd.DataFrame(columns = _columns)\n",
    "    pred_folder = Path(path_to_pred)\n",
    "    orig_folder = Path(path_to_orig)\n",
    "    resamp_folder = Path(path_to_resamp)\n",
    "    target_folder = Path(path_to_target)\n",
    "    file_folder = Path(path_to_file)\n",
    "    for ids in tqdm(subjects):\n",
    "        print(ids)\n",
    "        pred_sub = os.path.join(pred_folder, ids + '.npy.npz')\n",
    "        orig_sub = os.path.join(orig_folder, ids,'CT1_SEG.nii.gz')\n",
    "        resamp_sub = os.path.join(resamp_folder, ids,'CT1_SEG.nii.gz')\n",
    "        mat_fie_sub = os.path.join(file_folder, ids,'T1C_to_SRI_inv.mat')\n",
    "#         targets = nib.load(os.path.join(target_folder, ids + '_seg.nii.gz'))\n",
    "#         targets = ants.image_read(orig_sub)\n",
    "#         targets = ants.reorient_image2(label_orig, orientation = 'LAI')\n",
    "#         targets = nib.load(orig_sub)\n",
    "#         spaces = targets.header.get_zooms()\n",
    "#         spaces = targets.spacing\n",
    "#         targets = targets.numpy().astype('int')\n",
    "        targets = ants.image_read(f'{target_folder}/{ids}/CT1_SEG.nii.gz')\n",
    "        spaces = targets.spacing\n",
    "#         targets = ants.reorient_image2(targets, orientation = 'LAI').numpy()\n",
    "        targets = targets.numpy()\n",
    "#         print(targets.shape)\n",
    "#         print(np.unique(targets))\n",
    "        data = np.load(pred_sub, allow_pickle=True)['arr_0']\n",
    "#         print(data.shape)\n",
    "        if np.shape(data)[0] == 1: \n",
    "            prediction = pred_invert_resample_1cl(data, mat_fie_sub, orig_sub, resamp_sub, mod)\n",
    "            prediction = np.round(prediction, 0)\n",
    "#         pred = np.transpose(pred, (0, 3, 2, 1))\n",
    "#             print(prediction.shape)\n",
    "#             print(np.unique(prediction))\n",
    "            df = calculate_metrics_brats_1cl(targets.astype('int'), prediction.astype('int'), ids, spaces)\n",
    "#             print(df)\n",
    "        elif np.shape(data)[0] > 1: \n",
    "            prediction = pred_invert_resample_classes(data, mat_fie_sub, orig_sub, resamp_sub, mod)\n",
    "#             prediction = data.transpose(0,3,2,1).astype('float32')\n",
    "            prediction = np.round(prediction, 0)\n",
    "            y_wt, y_tc, y_et = targets > 0, ((targets == 1) + (targets == 3)) > 0, targets == 3\n",
    "            targets = np.stack([y_wt, y_tc, y_et], axis=0).astype(int)\n",
    "            print(targets.shape)\n",
    "#             print(prediction.shape)\n",
    "            df=calculate_metrics_brats(targets.astype('int'), prediction.astype('int'), ids, spaces)\n",
    "#             except:\n",
    "#                 continue\n",
    "        os.makedirs(os.path.join(out, dataset,ids), exist_ok = True)\n",
    "        out_path = os.path.join(out, dataset,ids, path_to_pred.split('/')[-2] + '_'+ path_to_pred.split('best_')[-1].replace('=', '_') + '.json')\n",
    "       #         df.to_json(out_path, orient='records')\n",
    "        sub_dict = {dataset : {path_to_pred.split('/')[-2]: {path_to_pred.split('_')[-2]: {}}}}\n",
    "        sub_dict[dataset][path_to_pred.split('/')[-2]][path_to_pred.split('_')[-2]] = df.to_dict('records')[0]\n",
    "#         print(sub_dict)\n",
    "#         with open(out_path, 'w') as fp:\n",
    "#             json.dump(sub_dict, fp)\n",
    "#         print(df)\n",
    "        af_all = af_all.append(df)\n",
    "#     af_all.to_csv(out)  \n",
    "    print(af_all.mean())\n",
    "    print(len(af_all))\n",
    "    return (sub_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a00ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_invert_resample_classes(data, mat_file_path, path_to_orig, path_to_resampled, mod):\n",
    "\n",
    "# gbm and lgg\n",
    "    data = data.transpose(0,3,2,1).astype('float32')\n",
    "#         print(data.shape)\n",
    "    old_orig_ct1 = ants.image_read(path_to_resampled)\n",
    "    new_orig_ct1 = ants.image_read(path_to_orig)\n",
    "\n",
    "#         print(old_orig_ct1.shape)\n",
    "#         print(new_orig_ct1.shape)\n",
    "    old_like_ch_0 = old_orig_ct1.new_image_like(data[0])\n",
    "    old_like_ch_1 = old_orig_ct1.new_image_like(data[1])\n",
    "    old_like_ch_2 = old_orig_ct1.new_image_like(data[2])\n",
    "#         print('old_like')\n",
    "# #         print(old_like_ch_2.shape)\n",
    "    if mod == '2a_interp':\n",
    "        new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.shape, True, 0)\n",
    "        new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.shape, True, 0)\n",
    "        new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.shape, True, 0)\n",
    "    if mod == '3a_atlas':\n",
    "        new_img_0 = ants.apply_transforms(new_orig_ct1, old_like_ch_0, whichtoinvert=[True],\n",
    "                                      transformlist = mat_file_path)\n",
    "        new_img_1 = ants.apply_transforms(new_orig_ct1, old_like_ch_1, whichtoinvert=[True],\n",
    "                                      transformlist = mat_file_path)\n",
    "        new_img_2 = ants.apply_transforms(new_orig_ct1, old_like_ch_2, whichtoinvert=[True],\n",
    "                                      transformlist = mat_file_path)\n",
    "    else:\n",
    "        new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.spacing, False, 0)\n",
    "        new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.spacing, False, 0)\n",
    "        new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.spacing, False, 0)\n",
    "\n",
    "    new_img_shape =  new_img_2.numpy().shape\n",
    "\n",
    "    new_array = np.zeros(tuple([3] + list(new_img_shape)), dtype='float16')\n",
    "    new_array[0] = new_img_0.numpy()\n",
    "    new_array[1] = new_img_1.numpy()\n",
    "    new_array[2] = new_img_2.numpy()\n",
    "    output_file = new_array.astype('float16')\n",
    "#         print(output_file.shape)\n",
    "#         print('check_shape')\n",
    "#         print(new_orig_ct1.shape)\n",
    "#         print(new_orig_ct1.shape[2]-output_file.shape[3])\n",
    "#         print((new_orig_ct1.shape[1]-output_file.shape[2]))\n",
    "#         print((new_orig_ct1.shape[0]-output_file.shape[1]))\n",
    "\n",
    "    # checks\n",
    "    if (new_orig_ct1.shape[2]-output_file.shape[3] < 0 ) or (new_orig_ct1.shape[1]-output_file.shape[2] < 0) or (new_orig_ct1.shape[0]-output_file.shape[1] < 0):\n",
    "        print(1)\n",
    "        output_file = output_file[:, :new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "\n",
    "    if (new_orig_ct1.shape[2]-output_file.shape[3] > 0) or (new_orig_ct1.shape[1]-output_file.shape[2] > 0 ) or (new_orig_ct1.shape[0]-output_file.shape[1] > 0):\n",
    "        print(2)\n",
    "        output_file = np.pad(output_file, ((0,0), (0, new_orig_ct1.shape[0]-output_file.shape[1]), (0, new_orig_ct1.shape[1]-output_file.shape[2]), (0, new_orig_ct1.shape[2]-output_file.shape[3])), 'constant', constant_values=0)\n",
    "\n",
    "    output_file = output_file[:,:new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "#         print(output_file.shape)\n",
    "\n",
    "    return (output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897f6974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_4b_n4_300',\n",
       " 'gbm_1_reg_train_from_bgpd_TL',\n",
       " 'gbm_4d_susan_from_bgpd_TL',\n",
       " 'gbm_5_ss_shared_from_bgpd_TL',\n",
       " 'gbm_6_histogram_unetr_300',\n",
       " '6_histogram_fold_2_from_bgpd_TL',\n",
       " 'gbm_4d_susan_unetr_300',\n",
       " 'gbm_5_ss_shared_from_egd_TL',\n",
       " 'gbm_3a_atlas_from_bgpd_TL',\n",
       " 'gbm_4a_resamp_unetr_param_wo_aug',\n",
       " '6_histogram_fold_0_from_bgpd_TL',\n",
       " 'gbm_4b_n4_from_bgpd_TL',\n",
       " '6_histogram_fold_1_from_bgpd_TL',\n",
       " 'gbm_3a_atlas_unetr',\n",
       " 'gbm_6_histogram_300',\n",
       " 'gbm_3a_atlas_from_brats_TL',\n",
       " 'gbm_4b_n4_from_bgpd_TL_last_bgpd',\n",
       " 'gbm_2a_interp_from_bgpd_TL',\n",
       " 'gbm_5_ss_shared_unetr_300',\n",
       " 'gbm_2a_interp_unetr',\n",
       " 'gbm_1_reg_train',\n",
       " 'gbm_2a_interp_300',\n",
       " 'gbm_4b_n4_unetr_300',\n",
       " 'gbm_1_reg_train_unetr',\n",
       " 'gbm_4a_resamp_from_bgpd_TL',\n",
       " 'gbm_4a_resamp_ct1_t2',\n",
       " 'gbm_3a_atlas_300',\n",
       " 'gbm_3a_atlas_from_egd_TL',\n",
       " 'gbm_4d_susan_300']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/newdata/gbm_infer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57d422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_folder = '/anvar/public_datasets/preproc_study/gbm/orig'\n",
    "resample_folder = '/anvar/public_datasets/preproc_study/gbm/4a_resamp'\n",
    "file_folder = '/anvar/public_datasets/preproc_study/gbm/3a_atlas'\n",
    "pred_folder = '/mnt/newdata/gbm_infer/gbm_4d_susan_300/'\n",
    "target_folder = '/anvar/public_datasets/preproc_study/gbm/1_reg'\n",
    "reg_1 = '/anvar/public_datasets/preproc_study/gbm/1_reg'\n",
    "out_json = '/results/metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e7db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T2.nii.gz',\n",
       " 'FLAIR.nii.gz',\n",
       " 'T1.nii.gz',\n",
       " 'CT1_SEG.nii.gz',\n",
       " 'CT1_mask.nii.gz',\n",
       " 'CT1.nii.gz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/anvar/public_datasets/preproc_study/gbm/5_ss_shared/TCGA-02-0054')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dcfc7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predictions_best_epoch=230-dice_mean=76_72_task=45_fold=0_tta'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(pred_folder)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2bdaafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictions_best_epoch=230-dice_mean=76_72_task=45_fold=0_tta',\n",
       " 'predictions_best_epoch=199-dice_mean=72_49_task=45_fold=1_tta',\n",
       " 'predictions_best_epoch=263-dice_mean=75_78_task=45_fold=2_tta']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/newdata/gbm_infer/gbm_4d_susan_300/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3903af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 'TCGA-02-0054'\n",
    "path_to_resampled = os.path.join('/anvar/public_datasets/preproc_study/gbm/4d_susan/', ids, 'CT1_SEG.nii.gz')\n",
    "mat_file_path = os.path.join(file_folder, ids,'T1C_to_SRI_inv.mat')\n",
    "path_to_orig = os.path.join('/anvar/public_datasets/preproc_study/gbm/orig', ids, 'CT1_SEG.nii.gz')\n",
    "pred_folder = '/mnt/newdata/gbm_infer/gbm_4d_susan_300/' + os.listdir(pred_folder)[0]\n",
    "mod = '4d_susan'\n",
    "\n",
    "# pred_invert_resample_classes(data, mat_file_path, orig_folder, resample_folder, mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ce6ac6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# gbm and lgg\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#         print(data.shape)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m old_orig_ct1 \u001b[38;5;241m=\u001b[39m ants\u001b[38;5;241m.\u001b[39mimage_read(path_to_resampled)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "data = ants.image_read(path_to_resampled)\n",
    "\n",
    "# gbm and lgg\n",
    "data = data.transpose(0,3,2,1).astype('float32')\n",
    "#         print(data.shape)\n",
    "old_orig_ct1 = ants.image_read(path_to_resampled)\n",
    "new_orig_ct1 = ants.image_read(path_to_orig)\n",
    "\n",
    "#         print(old_orig_ct1.shape)\n",
    "#         print(new_orig_ct1.shape)\n",
    "old_like_ch_0 = old_orig_ct1.new_image_like(data[0])\n",
    "old_like_ch_1 = old_orig_ct1.new_image_like(data[1])\n",
    "old_like_ch_2 = old_orig_ct1.new_image_like(data[2])\n",
    "#         print('old_like')\n",
    "# #         print(old_like_ch_2.shape)\n",
    "if mod == '2a_interp':\n",
    "    new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.shape, True, 0)\n",
    "    new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.shape, True, 0)\n",
    "    new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.shape, True, 0)\n",
    "if mod == '3a_atlas':\n",
    "    new_img_0 = ants.apply_transforms(new_orig_ct1, old_like_ch_0, whichtoinvert=[True],\n",
    "                                  transformlist = mat_file_path)\n",
    "    new_img_1 = ants.apply_transforms(new_orig_ct1, old_like_ch_1, whichtoinvert=[True],\n",
    "                                  transformlist = mat_file_path)\n",
    "    new_img_2 = ants.apply_transforms(new_orig_ct1, old_like_ch_2, whichtoinvert=[True],\n",
    "                                  transformlist = mat_file_path)\n",
    "else:\n",
    "    new_img_0 = ants.resample_image(old_like_ch_0, new_orig_ct1.spacing, False, 0)\n",
    "    new_img_1 = ants.resample_image(old_like_ch_1, new_orig_ct1.spacing, False, 0)\n",
    "    new_img_2 = ants.resample_image(old_like_ch_2, new_orig_ct1.spacing, False, 0)\n",
    "\n",
    "new_img_shape =  new_img_2.numpy().shape\n",
    "\n",
    "new_array = np.zeros(tuple([3] + list(new_img_shape)), dtype='float16')\n",
    "new_array[0] = new_img_0.numpy()\n",
    "new_array[1] = new_img_1.numpy()\n",
    "new_array[2] = new_img_2.numpy()\n",
    "output_file = new_array.astype('float16')\n",
    "#         print(output_file.shape)\n",
    "#         print('check_shape')\n",
    "#         print(new_orig_ct1.shape)\n",
    "#         print(new_orig_ct1.shape[2]-output_file.shape[3])\n",
    "#         print((new_orig_ct1.shape[1]-output_file.shape[2]))\n",
    "#         print((new_orig_ct1.shape[0]-output_file.shape[1]))\n",
    "\n",
    "# checks\n",
    "if (new_orig_ct1.shape[2]-output_file.shape[3] < 0 ) or (new_orig_ct1.shape[1]-output_file.shape[2] < 0) or (new_orig_ct1.shape[0]-output_file.shape[1] < 0):\n",
    "    print(1)\n",
    "    output_file = output_file[:, :new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "\n",
    "if (new_orig_ct1.shape[2]-output_file.shape[3] > 0) or (new_orig_ct1.shape[1]-output_file.shape[2] > 0 ) or (new_orig_ct1.shape[0]-output_file.shape[1] > 0):\n",
    "    print(2)\n",
    "    output_file = np.pad(output_file, ((0,0), (0, new_orig_ct1.shape[0]-output_file.shape[1]), (0, new_orig_ct1.shape[1]-output_file.shape[2]), (0, new_orig_ct1.shape[2]-output_file.shape[3])), 'constant', constant_values=0)\n",
    "\n",
    "output_file = output_file[:,:new_orig_ct1.shape[0], :new_orig_ct1.shape[1],:new_orig_ct1.shape[2] ]\n",
    "#         print(output_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebf7a3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256, 256, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa9630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0623a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_predicts_ss = Path('/anvar/public_datasets/preproc_study/gbm/inference/native_space/5_ss')\n",
    "folder_predicts_atlas = Path('/anvar/public_datasets/preproc_study/gbm/inference/native_space/3a_atlas')\n",
    "folds = Path('/home/anvar/projects/brain-mri-processing-pipeline/main_pipeline/utils')\n",
    "folder_mask = Path('/anvar/public_datasets/preproc_study/gbm/1_reg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e95e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_folder = '/anvar/public_datasets/preproc_study/gbm/orig'\n",
    "resample_folder = '/data_anvar/public_datasets/preproc_study/gbm/4a_resamp'\n",
    "file = '/anvar/public_datasets/preproc_study/gbm/3a_atlas'\n",
    "pred_folder = '/mnt/newdata/gbm_infer/gbm_5_ss_shared_from_bgpd_TL/predictions_best_epoch=40-dice_mean=82_24_task=28_fold=2_tta'\n",
    "target_folder = '/anvar/public_datasets/preproc_study/gbm/1_reg'\n",
    "reg_1 = '/anvar/public_datasets/preproc_study/gbm/1_reg'\n",
    "out_json = '/results/metrics'\n",
    "dataset = 'gbm'\n",
    "# TCGA-76-4932\n",
    "subjects = [each[:-8] for each in os.listdir(pred_folder)]\n",
    "assert(len(subjects) == 102)\n",
    "# subjects = ['TCGA-02-0027']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8e84826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCGA-06-0164'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641726f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "calculate_metrics([subjects[0]], file, reg_1, pred_folder, resample_folder, target_folder, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b2d0ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2997777125.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ось х в милилитрах, а y в процентах\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ось х в милилитрах, а y в процентах\n",
    "ошибка в дайсе и нет ошибки в объемах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707d2ad5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(pred_sub, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#         print(data.shape)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(data)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "data = np.load(pred_sub, allow_pickle=True)['arr_0']\n",
    "#         print(data.shape)\n",
    "if np.shape(data)[0] == 1: \n",
    "    prediction = pred_invert_resample_1cl(data, mat_fie_sub, orig_sub, resamp_sub, mod)\n",
    "    prediction = np.round(prediction, 0)\n",
    "#         pred = np.transpose(pred, (0, 3, 2, 1))\n",
    "#             print(prediction.shape)\n",
    "#             print(np.unique(prediction))\n",
    "    df = calculate_metrics_brats_1cl(targets.astype('int'), prediction.astype('int'), ids, spaces)\n",
    "#             print(df)\n",
    "elif np.shape(data)[0] > 1: \n",
    "    prediction = pred_invert_resample_classes(data, mat_fie_sub, orig_sub, resamp_sub, mod)\n",
    "#             prediction = data.transpose(0,3,2,1).astype('float32')\n",
    "    prediction = np.round(prediction, 0)\n",
    "    y_wt, y_tc, y_et = targets > 0, ((targets == 1) + (targets == 3)) > 0, targets == 3\n",
    "    targets = np.stack([y_wt, y_tc, y_et], axis=0).astype(int)\n",
    "    print(targets.shape)\n",
    "#             print(prediction.shape)\n",
    "    df = calculate_metrics_brats(targets.astype('int'), prediction.astype('int'), ids, spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78447f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
