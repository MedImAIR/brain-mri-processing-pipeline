{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e426c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from skimage.transform import rescale\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import researchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44edcbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def compute_kl(img, brain, mask, _bin_heuristics = 'sturges'):\n",
    "    size, _bins = np.histogram(img[brain.astype(bool)], bins = _bin_heuristics)\n",
    "    bins = [(_bins[i]+_bins[i+1])/2 for i in range(len(_bins)-1)]\n",
    "    # WT\n",
    "    #size_healthy, bin_edges = np.histogram(img[brain.astype(bool)^mask.astype(bool)].reshape(-1), bins=_bins)\n",
    "    # TC\n",
    "    size_healthy, bin_edges = np.histogram(img[brain.astype(bool)^(mask == 2)].reshape(-1), bins=_bins)\n",
    "    # ET\n",
    "    size_tumor, _ = np.histogram(img[mask.astype(bool)].reshape(-1), bins = _bins)\n",
    "    size_healthy = np.round(size_healthy/size_healthy.sum(), 5)\n",
    "    size_tumor = np.round(size_tumor/size_tumor.sum(), 5)\n",
    "    \n",
    "    size_healthy = np.where(size_healthy>10e-6, size_healthy, 10e-6)\n",
    "    size_tumor = np.where(size_tumor>10e-6, size_tumor, 10e-6)\n",
    "\n",
    "    kl_dist = 0\n",
    "    for h,t in zip(size_healthy, size_tumor):\n",
    "        kl_dist += h * np.log2(h/t)\n",
    "\n",
    "#     kl_dist = scipy.spatial.distance.jensenshannon(size_healthy, size_tumor)            \n",
    "    return kl_dist, size_healthy, size_tumor, _bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4a31dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "def coef_of_var(img, brain, mask):\n",
    "    \"\"\"\n",
    "    where σ is standard deviation, and µ is mean of a region\n",
    "    of interest, which was the prostate for the purposes of this study.\n",
    "    \"\"\"\n",
    "    tumor_roi = img[brain.astype(bool)^mask.astype(bool)].reshape(-1)\n",
    "    return np.round((np.std(tumor_roi)/np.mean(tumor_roi)),3)\n",
    "\n",
    "def snr_roi(img, brain, mask):\n",
    "    \"\"\"\n",
    "    where σ is standard deviation, and µ is mean of a region\n",
    "    of interest, which was the prostate for the purposes of this study.\n",
    "    \"\"\"\n",
    "    tumor_roi = img[brain.astype(bool)^mask.astype(bool)].reshape(-1)\n",
    "    return np.round(np.mean(tumor_roi)/np.std(tumor_roi),3)\n",
    "    #return np.round(np.std(tumor_roi),3)\n",
    "\n",
    "\n",
    "def calculate_psnr(img1, img2, brain, mask):\n",
    "    \"\"\" img1 - w/o noise, img2 with noise\n",
    "    implementation from here https://cvnote.ddlee.cc/2019/09/12/psnr-ssim-python\"\"\"\n",
    "    tumor_roi1 = img1[brain.astype(bool)^mask.astype(bool)].reshape(-1)\n",
    "    tumor_roi2 = img2[brain.astype(bool)^mask.astype(bool)].reshape(-1)\n",
    "    mse = np.mean((tumor_roi1 - tumor_roi2)**2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(255.0 / math.sqrt(mse))\n",
    "\n",
    "\n",
    "def diff_of_modes(img, img_hist, brain):\n",
    "    \n",
    "    \"\"\"\n",
    "    where ω test is the principal mode of the intensity distribution\n",
    "    of an MR image undergoing IS, and ω\n",
    "    temp is the principal mode of the template intensity distribution that is being\n",
    "    standardized against. \n",
    "    \"\"\"\n",
    "    brain_test = img[brain.astype(bool)].reshape(-1)\n",
    "    brain_temp = img_hist[brain.astype(bool)].reshape(-1)\n",
    "    \n",
    "    diff = abs(stats.mode(brain_test) - stats.mode(brain_temp))/stats.mode(brain_temp)\n",
    "    return np.round(diff, 3)\n",
    "\n",
    "from researchpy import ttest\n",
    "\n",
    "def ttest_pair(df_1, df_2, name_1 = 'one', name_2 = 'two', correction = None):\n",
    "    return ttest(pd.Series(df_1), pd.Series(df_2), \n",
    "#                  group1_name = name_1,\n",
    "#                  group2_name= name_2, \n",
    "                 equal_variances=False, paired=True,)[1].iloc[4].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f976f2",
   "metadata": {},
   "source": [
    "### 4a resamp to 4b N4: Coef of variance\n",
    "\n",
    "a. T2\n",
    "b. CT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87b7cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [01:48,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = 'gbm'\n",
    "main_img = 'CT1.nii.gz'\n",
    "label_name = 'CT1_SEG.nii.gz'\n",
    "mask_name = 'CT1_mask.nii.gz'\n",
    "\n",
    "root = Path('/anvar/public_datasets/preproc_study/{}/4a_resamp/'.format(dataset)) \n",
    "root_test = Path('/anvar/public_datasets/preproc_study/{}/6_hist/6_hist_fold_0/'.format(dataset))\n",
    "root_brain = Path('/anvar/public_datasets/preproc_study/{}/5_ss_shared/'.format(dataset))\n",
    "\n",
    "all_orig = []\n",
    "all_bfc = []\n",
    "\n",
    "for patient in tqdm(root.glob('*')):\n",
    "    if patient.is_dir():\n",
    "        img = nibabel.load(patient / main_img).get_fdata()\n",
    "        mask = nibabel.load(patient / label_name).get_fdata()\n",
    "        brain = nibabel.load(str(root_brain) + '/' +\n",
    "                             str(patient).split('/')[-1] +'/' + mask_name).get_fdata()\n",
    "        \n",
    "        img_temp = nibabel.load(str(root_test) +'/' +\n",
    "                             str(patient).split('/')[-1] +'/' + main_img).get_fdata()\n",
    "        \n",
    "        coef_orig = coef_of_var(img, brain, mask)\n",
    "        all_orig.append(coef_orig)\n",
    "        \n",
    "        coef_bfc = coef_of_var(img_temp, brain, mask)\n",
    "        all_bfc.append(coef_bfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7835503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from researchpy import ttest\n",
    "\n",
    "def ttest_pair(df_1, df_2, name_1 = 'one', name_2 = 'two', correction = None):\n",
    "    return ttest(pd.Series(df_1), pd.Series(df_2), \n",
    "#                  group1_name = name_1,\n",
    "#                  group2_name= name_2, \n",
    "                 equal_variances=False, paired=True,)[1].iloc[4].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4648382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24193137254901956,\n",
       " 0.062488000385944154,\n",
       " 0.3103725490196078,\n",
       " 0.11983173837073999,\n",
       " 0.0008)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 46_hist\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_bfc).mean(), np.array(all_bfc).std(), ttest_pair(all_orig, all_bfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b1fe938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24193137254901956,\n",
       " 0.062488000385944154,\n",
       " 0.23681372549019614,\n",
       " 0.061749927425877316,\n",
       " 0.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 4d_susan\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_bfc).mean(), np.array(all_bfc).std(), ttest_pair(all_orig, all_bfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aecf7e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333137254901961,\n",
       " 0.0753851522792117,\n",
       " 0.31238235294117656,\n",
       " 0.07588355942193341)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM T2 4b_n4\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_bfc).mean(), np.array(all_bfc).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a73554d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24193137254901956,\n",
       " 0.062488000385944154,\n",
       " 0.22451960784313726,\n",
       " 0.06060119237682763)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 4b_n4\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_bfc).mean(), np.array(all_bfc).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fde2e9",
   "metadata": {},
   "source": [
    "### 4a resamp to 4d SUSAN: SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14a85e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def snr_roi(img, brain, mask):\n",
    "    \"\"\"\n",
    "    where σ is standard deviation, and µ is mean of a region\n",
    "    of interest, which was the prostate for the purposes of this study.\n",
    "    \n",
    "    if calculated for tumor region - it deacrease everything\n",
    "    \"\"\"\n",
    "    tumor_roi = img[brain.astype(bool)].reshape(-1)\n",
    "    return np.round(np.mean(tumor_roi)/np.std(tumor_roi),3)\n",
    "    #return np.round(np.std(tumor_roi),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ffceca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [01:26,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = 'gbm'\n",
    "main_img = 'CT1.nii.gz'\n",
    "label_name = 'CT1_SEG.nii.gz'\n",
    "mask_name = 'CT1_mask.nii.gz'\n",
    "\n",
    "root = Path('/anvar/public_datasets/preproc_study/{}/4a_resamp/'.format(dataset)) \n",
    "root_test = Path('/anvar/public_datasets/preproc_study/{}/6_hist/6_hist_fold_0/'.format(dataset))\n",
    "root_brain = Path('/anvar/public_datasets/preproc_study/{}/5_ss_shared/'.format(dataset))\n",
    "\n",
    "all_orig = []\n",
    "all_nf = []\n",
    "\n",
    "for patient in tqdm(root.glob('*')):\n",
    "    if patient.is_dir():\n",
    "        img = nibabel.load(patient / main_img).get_fdata()\n",
    "        mask = nibabel.load(patient / label_name).get_fdata()\n",
    "        brain = nibabel.load(str(root_brain) + '/' +\n",
    "                             str(patient).split('/')[-1] +'/' + mask_name).get_fdata()\n",
    "        \n",
    "        img_temp = nibabel.load(str(root_test) +'/' +\n",
    "                             str(patient).split('/')[-1] +'/' + main_img).get_fdata()\n",
    "        \n",
    "        coef_orig = snr_roi(img, brain, mask)\n",
    "        all_orig.append(coef_orig)\n",
    "        \n",
    "        coef_nf = snr_roi(img_temp, brain, mask)\n",
    "        all_nf.append(coef_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2e1a04b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.20636274509804,\n",
       " 0.9766134843569172,\n",
       " 3.524647058823529,\n",
       " 1.1610088382485937,\n",
       " 0.001)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 hist\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_nf).mean(), np.array(all_nf).std(), ttest_pair(all_orig, all_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83b8c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.20636274509804,\n",
       " 0.9766134843569172,\n",
       " 4.568303921568627,\n",
       " 1.0966708873142665,\n",
       " 0.0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 4b_n4\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_nf).mean(), np.array(all_nf).std(), ttest_pair(all_orig, all_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b0b406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.20636274509804,\n",
       " 0.9766134843569172,\n",
       " 4.2941078431372555,\n",
       " 1.003528431036844,\n",
       " 0.0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 4d_susan\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_nf).mean(), np.array(all_nf).std(), ttest_pair(all_orig, all_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13739f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129.08098039215685,\n",
       " 153.4854274961186,\n",
       " 127.78495098039217,\n",
       " 153.68665577040107,\n",
       " 0.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_nf).mean(), np.array(all_nf).std(), ttest_pair(all_orig, all_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "837d7b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169.56006862745102, 105.93496562479578, 168.4317058823529, 106.1864894376397)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM T2\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_nf).mean(), np.array(all_nf).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333280b4",
   "metadata": {},
   "source": [
    "## PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eabb35a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [01:20,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = 'gbm'\n",
    "main_img = 'CT1.nii.gz'\n",
    "label_name = 'CT1_SEG.nii.gz'\n",
    "mask_name = 'CT1_mask.nii.gz'\n",
    "\n",
    "root = Path('/anvar/public_datasets/preproc_study/{}/4a_resamp/'.format(dataset)) \n",
    "root_test = Path('/anvar/public_datasets/preproc_study/{}/4b_n4/'.format(dataset))\n",
    "root_brain = Path('/anvar/public_datasets/preproc_study/{}/5_ss_shared/'.format(dataset))\n",
    "\n",
    "all_psnr = []\n",
    "\n",
    "for patient in tqdm(root.glob('*')):\n",
    "    if patient.is_dir():\n",
    "        img = nibabel.load(patient / main_img).get_fdata()\n",
    "        mask = nibabel.load(patient / label_name).get_fdata()\n",
    "        brain = nibabel.load(str(root_brain) + '/' +\n",
    "                             str(patient).split('/')[-1] +'/' + mask_name).get_fdata()\n",
    "        \n",
    "        img_temp = nibabel.load(str(root_test) +'/' +\n",
    "                             str(patient).split('/')[-1] +'/' + main_img).get_fdata()\n",
    "        \n",
    "        coef_psnr = calculate_psnr(img, img_temp, brain, mask)\n",
    "        all_psnr.append(coef_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#susan\n",
    "np.array(all_psnr).mean(), np.array(all_psnr).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d240990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n4\n",
    "np.array(all_psnr).mean(), np.array(all_psnr).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46f26a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.5115249944443252, 9.350359089366194)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hist\n",
    "np.array(all_psnr).mean(), np.array(all_psnr).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e873db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## could be checked from here https://scikit-image.org/docs/stable/api/skimage.metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4602e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "131ebbde",
   "metadata": {},
   "source": [
    "### 4a resamp to 6 hist: diff of modes and KL to the mean hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a200ad0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For landmarks there are  102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03ff7a37e5a4b4eb61573650182d2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef94a65bc0490ea4a10a30c9de23de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eb0e26a78c4012a345f6d81be4cf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca51ec0ecaa04a06b49d69a2f18c98be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchio.transforms import HistogramStandardization\n",
    "\n",
    "base_dir = '/anvar/public_datasets/preproc_study/gbm/4a_resamp/'\n",
    "save_dir = '/anvar/public_datasets/preproc_study/gbm/6_hist/6_hist_fold_0/'\n",
    "mask_name = 'CT1_SEG.nii.gz'\n",
    "\n",
    "# Separate dataset for each fold\n",
    "# Create dataset\n",
    "temp_t1_list = []\n",
    "temp_t2_list = []\n",
    "temp_ct1_list = []\n",
    "temp_fl_list = []\n",
    "\n",
    "for patient in os.listdir(base_dir):\n",
    "    if os.path.isdir(base_dir + patient):\n",
    "        temp_t1_list.append(base_dir + patient + '/T1.nii.gz')\n",
    "        temp_t2_list.append(base_dir + patient + '/T2.nii.gz')\n",
    "        temp_ct1_list.append(base_dir + patient + '/CT1.nii.gz')\n",
    "        temp_fl_list.append(base_dir + patient + '/FLAIR.nii.gz')\n",
    "#             print(len(subjects_list))\n",
    "\n",
    "print('For landmarks there are ', len(temp_t1_list))\n",
    "# logging.info(\"Training T1 landmarks started.\")\n",
    "t1_landmarks = HistogramStandardization.train(temp_t1_list)\n",
    "# logging.info(\"Training T2 landmarks started.\")\n",
    "t2_landmarks = HistogramStandardization.train(temp_t2_list)\n",
    "# logging.info(\"Training CT1 landmarks started.\")\n",
    "ct1_landmarks = HistogramStandardization.train(temp_ct1_list)\n",
    "# logging.info(\"Training FLAIR landmarks started.\")\n",
    "fl_landmarks = HistogramStandardization.train(temp_fl_list)\n",
    "\n",
    "# Saving landmarks\n",
    "landmarks_dict = {\n",
    "'t1': t1_landmarks,\n",
    "'t2': t2_landmarks,\n",
    "'ct1': ct1_landmarks,\n",
    "'fl': fl_landmarks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05d22a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "hist_standardization = tio.HistogramStandardization(landmarks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17437fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardizing one template subject\n",
    "patient = 'TCGA-02-0086'\n",
    "subject = tio.Subject(\n",
    "            t1 = tio.ScalarImage(base_dir + patient + '/T1.nii.gz'),\n",
    "            t2 = tio.ScalarImage(base_dir + patient + '/T2.nii.gz'),\n",
    "            # can be commented for other datasets\n",
    "            ct1 = tio.ScalarImage(base_dir + patient + '/CT1.nii.gz'),\n",
    "            fl = tio.ScalarImage(base_dir + patient + '/FLAIR.nii.gz')\n",
    "        )\n",
    "# hist standartize for the four landmarks\n",
    "hist_standardize = hist_standardization(subject)\n",
    "# saving forewer here in the folder\n",
    "hist_standardize['t1'].save('T1_gbm_hist.nii.gz')\n",
    "hist_standardize['t2'].save('T2_gbm_hist.nii.gz')\n",
    "hist_standardize['fl'].save('FLAIR_gbm_hist.nii.gz')\n",
    "hist_standardize['ct1'].save('CT1_gbm_hist.nii.gz')\n",
    "\n",
    "hist_temp = nibabel.load('CT1_gbm_hist.nii.gz').get_fdata()\n",
    "brain_hist = nibabel.load(str(root_brain) + '/' + str(patient).split('/')[-1] +'/' + mask_name).get_fdata()\n",
    "img_hist_mode = stats.mode(hist_temp[brain_hist.astype(bool)].reshape(-1), keepdims = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa817a2",
   "metadata": {},
   "source": [
    "### diff of modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36c5cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_of_modes(img, img_hist_mode, brain):\n",
    "    \n",
    "    \"\"\"\n",
    "    where ω test is the principal mode of the intensity distribution\n",
    "    of an MR image undergoing IS, and ω\n",
    "    temp is the principal mode of the template intensity distribution that is being\n",
    "    standardized against. \n",
    "    \"\"\"\n",
    "    brain_test = img[brain.astype(bool)].reshape(-1)\n",
    "    \n",
    "    diff = abs(stats.mode(brain_test, keepdims = False)[0] - img_hist_mode[0])/img_hist_mode[0]\n",
    "    return np.round(diff, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "13d7437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_12306/3912426824.py:11: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  diff = abs(stats.mode(brain_test)[0] - img_hist_mode[0])/img_hist_mode[0]\n",
      "102it [01:53,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = 'gbm'\n",
    "main_img = 'CT1.nii.gz'\n",
    "label_name = 'CT1_SEG.nii.gz'\n",
    "mask_name = 'CT1_mask.nii.gz'\n",
    "\n",
    "root = Path('/anvar/public_datasets/preproc_study/{}/4a_resamp/'.format(dataset)) \n",
    "root_test = Path('/anvar/public_datasets/preproc_study/{}/4b_n4'.format(dataset))\n",
    "root_brain = Path('/anvar/public_datasets/preproc_study/{}/5_ss_shared/'.format(dataset))\n",
    "\n",
    "all_orig = []\n",
    "all_hist = []\n",
    "\n",
    "for patient in tqdm(root.glob('*')):\n",
    "    if patient.is_dir():\n",
    "        img = nibabel.load(patient / main_img).get_fdata()\n",
    "        mask = nibabel.load(patient / label_name).get_fdata()\n",
    "        brain = nibabel.load(str(root_brain) + '/' +\n",
    "                             str(patient).split('/')[-1] +'/' + mask_name).get_fdata()\n",
    "        \n",
    "        img_temp = nibabel.load(str(root_test) +'/' +\n",
    "                             str(patient).split('/')[-1] +'/' + main_img).get_fdata()\n",
    "        \n",
    "        coef_orig = diff_of_modes(img, img_hist_mode, brain)\n",
    "        all_orig.append(coef_orig)\n",
    "        \n",
    "        coef_hist = diff_of_modes(img_temp, img_hist_mode, brain)\n",
    "        all_hist.append(coef_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27068924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.696058823529416,\n",
       " 21.770764256908237,\n",
       " 20.43320588235294,\n",
       " 22.11269927667696,\n",
       " 0.0076)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 4b_n4\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_hist).mean(), np.array(all_hist).std(), ttest_pair(all_orig, all_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5644cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/lib/python3.9/site-packages/researchpy/ttest.py:38: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  groups = group1.append(group2, ignore_index= True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.696058823529416,\n",
       " 21.770764256908237,\n",
       " 21.487970588235296,\n",
       " 24.84921863783446,\n",
       " 0.0111)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1 4d_susan\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_hist).mean(), np.array(all_hist).std(), ttest_pair(all_orig, all_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fda0ec51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.696058823529416,\n",
       " 21.770764256908237,\n",
       " 0.6849019607843135,\n",
       " 0.3470235769185313)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM CT1\n",
    "np.array(all_orig).mean(), np.array(all_orig).std(), np.array(all_hist).mean(), np.array(all_hist).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364ca7a",
   "metadata": {},
   "source": [
    "### KL of mean hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79da34",
   "metadata": {},
   "source": [
    "4-4b SNR, 4-4a средняя гистограмма по 4а ресемп (для неё нужно зафиксировать бины, 102 + 1 гистограмма для датасета). Гистограамы должны быть нормализованы (суммироваться в единицу normalize true работает правильно) 102 и разница от среднего. И среднее расстояние после Hist Matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'gbm'\n",
    "main_img = '/FLAIR.nii.gz'\n",
    "label_name = 'mask_GTV_FLAIR.nii.gz'\n",
    "mask_name = 'FLAIR_mask.nii.gz'\n",
    "root = '/anvar/public_datasets/preproc_study/{}/6_hist/6_hist_fold_0/'.format(dataset)\n",
    "root_orig = '/anvar/public_datasets/preproc_study/{}/4a_resamp/'.format(dataset)\n",
    "\n",
    "def calc_cdf(t1_image, bins = 100):\n",
    "    \"\"\" Takes np.array 3D size as input\n",
    "    Outputting CDFs and cumsum of the normalised and original images\"\"\"\n",
    "\n",
    "    masked_img = t1_image.reshape(-1)\n",
    "    t1_hist, t1_hist_bins = np.histogram(masked_img, bins= bins)\n",
    "    cumsum = np.cumsum(t1_hist)\n",
    "    return t1_hist_bins[:-1], (cumsum- cumsum.min())/cumsum.sum()\n",
    "\n",
    "plt.figure(figsize = [10,4])\n",
    "\n",
    "for patient in tqdm.tqdm(os.listdir(root)[30:70]):\n",
    "        img = sitk.GetArrayFromImage(sitk.ReadImage(root + patient + main_img))\n",
    "        brain_mask = sitk.GetArrayFromImage(sitk.ReadImage('/anvar/public_datasets/preproc_study/{}/5_ss_shared/'.format(dataset) +\n",
    "                             str(patient).split('/')[-1] +'/' + mask_name))\n",
    "        bins_cdf, cdf =  calc_cdf(img[brain_mask.astype(bool)], bins = 100)\n",
    "        plt.plot(bins_cdf, cdf, '-', drawstyle='steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d528c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
