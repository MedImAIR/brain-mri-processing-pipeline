{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_1_3 = pd.read_csv('results/main_table.tsv',  sep='\\t')\n",
    "df_4_bgpd_gbm = pd.read_csv('results/transfer_bgpd_gbm.tsv',  sep='\\t')\n",
    "df_4_gbm_bgpd = pd.read_csv('results/transfer_gbm_bgpd.tsv',  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Preprocessing step</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>NN-Architecture (nn-Unet, UNETR)</th>\n",
       "      <th>Label (WT, ET, TC, GTV)</th>\n",
       "      <th>Dice</th>\n",
       "      <th>Hausdorff</th>\n",
       "      <th>Surface Dice 1mm</th>\n",
       "      <th>Surface Dice 3mm</th>\n",
       "      <th>Surface Dice 5mm</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Volume_estimated</th>\n",
       "      <th>Volume_intersection</th>\n",
       "      <th>Volume_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCGA-02-0011</td>\n",
       "      <td>1_reg</td>\n",
       "      <td>gbm</td>\n",
       "      <td>nn_unet</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.290</td>\n",
       "      <td>39.000</td>\n",
       "      <td>0.264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>25.748</td>\n",
       "      <td>22.114</td>\n",
       "      <td>126.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCGA-02-0011</td>\n",
       "      <td>1_reg</td>\n",
       "      <td>gbm</td>\n",
       "      <td>nn_unet</td>\n",
       "      <td>ET</td>\n",
       "      <td>0.138</td>\n",
       "      <td>39.000</td>\n",
       "      <td>0.218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>2.983</td>\n",
       "      <td>22.114</td>\n",
       "      <td>33.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCGA-02-0011</td>\n",
       "      <td>1_reg</td>\n",
       "      <td>gbm</td>\n",
       "      <td>nn_unet</td>\n",
       "      <td>TC</td>\n",
       "      <td>0.030</td>\n",
       "      <td>34.300</td>\n",
       "      <td>0.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>9.525</td>\n",
       "      <td>22.114</td>\n",
       "      <td>81.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGA-02-0033</td>\n",
       "      <td>1_reg</td>\n",
       "      <td>gbm</td>\n",
       "      <td>nn_unet</td>\n",
       "      <td>WT</td>\n",
       "      <td>0.242</td>\n",
       "      <td>39.000</td>\n",
       "      <td>0.261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>19.781</td>\n",
       "      <td>14.996</td>\n",
       "      <td>104.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCGA-02-0033</td>\n",
       "      <td>1_reg</td>\n",
       "      <td>gbm</td>\n",
       "      <td>nn_unet</td>\n",
       "      <td>ET</td>\n",
       "      <td>0.265</td>\n",
       "      <td>26.094</td>\n",
       "      <td>0.330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>6.324</td>\n",
       "      <td>14.996</td>\n",
       "      <td>31.703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientID Preprocessing step Dataset NN-Architecture (nn-Unet, UNETR)  \\\n",
       "0  TCGA-02-0011              1_reg     gbm                          nn_unet   \n",
       "1  TCGA-02-0011              1_reg     gbm                          nn_unet   \n",
       "2  TCGA-02-0011              1_reg     gbm                          nn_unet   \n",
       "3  TCGA-02-0033              1_reg     gbm                          nn_unet   \n",
       "4  TCGA-02-0033              1_reg     gbm                          nn_unet   \n",
       "\n",
       "  Label (WT, ET, TC, GTV)   Dice  Hausdorff  Surface Dice 1mm  \\\n",
       "0                      WT  0.290     39.000             0.264   \n",
       "1                      ET  0.138     39.000             0.218   \n",
       "2                      TC  0.030     34.300             0.133   \n",
       "3                      WT  0.242     39.000             0.261   \n",
       "4                      ET  0.265     26.094             0.330   \n",
       "\n",
       "   Surface Dice 3mm  Surface Dice 5mm  Epoch  Volume_estimated  \\\n",
       "0               NaN               NaN    300            25.748   \n",
       "1               NaN               NaN    300             2.983   \n",
       "2               NaN               NaN    300             9.525   \n",
       "3               NaN               NaN    300            19.781   \n",
       "4               NaN               NaN    300             6.324   \n",
       "\n",
       "   Volume_intersection  Volume_true  \n",
       "0               22.114      126.783  \n",
       "1               22.114       33.488  \n",
       "2               22.114       81.619  \n",
       "3               14.996      104.407  \n",
       "4               14.996       31.703  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Table 4: \n",
    "\n",
    "reindex_list = ['1_reg', '2a_interp', '3a_atlas', '4a_resamp', '4b_n4', '4d_susan','6_hist','5_ss_shared']\n",
    "rename_list = ['1. Inter modality', '2. Resampling', '3. Atlas', '4. Resampling to spacing', '4.a Bias', '4.b Denoising', '4.c Histogram', '4.d Skull']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gbm', 'bgpd', 'lgg'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_3.Dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По каждой метрике проверяем на gbm, bgpd, lgg. Делаем для nnU-net и unetr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICE scores\n",
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Dice\n",
      "1. Inter modality           44.0 (28.0)\n",
      "2. Resampling               85.0 (11.0)\n",
      "3. Atlas                    85.0 (11.0)\n",
      "4. Resampling to spacing    85.0 (12.0)\n",
      "4.a Bias                    82.0 (13.0)\n",
      "4.b Denoising               84.0 (12.0)\n",
      "4.c Histogram               83.0 (16.0)\n",
      "4.d Skull                   87.0 (11.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd nn_unet Dice\n",
      "1. Inter modality           36.0 (29.0)\n",
      "2. Resampling               73.0 (19.0)\n",
      "3. Atlas                    75.0 (16.0)\n",
      "4. Resampling to spacing    74.0 (18.0)\n",
      "4.a Bias                    75.0 (17.0)\n",
      "4.b Denoising               74.0 (17.0)\n",
      "4.c Histogram               75.0 (16.0)\n",
      "4.d Skull                   76.0 (14.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "lgg nn_unet Dice\n",
      "1. Inter modality           67.0 (27.0)\n",
      "2. Resampling               72.0 (24.0)\n",
      "3. Atlas                    71.0 (25.0)\n",
      "4. Resampling to spacing    70.0 (25.0)\n",
      "4.a Bias                    67.0 (25.0)\n",
      "4.b Denoising               70.0 (25.0)\n",
      "4.c Histogram               68.0 (26.0)\n",
      "4.d Skull                   77.0 (21.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "=======================NEW MODEL=======================\n",
      "gbm UNETR Dice\n",
      "1. Inter modality           39.0 (26.0)\n",
      "2. Resampling               82.0 (12.0)\n",
      "3. Atlas                    82.0 (13.0)\n",
      "4. Resampling to spacing    82.0 (14.0)\n",
      "4.a Bias                    80.0 (13.0)\n",
      "4.b Denoising               83.0 (13.0)\n",
      "4.c Histogram               81.0 (16.0)\n",
      "4.d Skull                   85.0 (10.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd UNETR Dice\n",
      "1. Inter modality           34.0 (30.0)\n",
      "2. Resampling               67.0 (20.0)\n",
      "3. Atlas                    68.0 (21.0)\n",
      "4. Resampling to spacing    67.0 (21.0)\n",
      "4.a Bias                    72.0 (19.0)\n",
      "4.b Denoising               69.0 (21.0)\n",
      "4.c Histogram               68.0 (18.0)\n",
      "4.d Skull                   72.0 (18.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "lgg UNETR Dice\n",
      "1. Inter modality           66.0 (23.0)\n",
      "2. Resampling               66.0 (26.0)\n",
      "3. Atlas                    67.0 (25.0)\n",
      "4. Resampling to spacing    67.0 (23.0)\n",
      "4.a Bias                    62.0 (22.0)\n",
      "4.b Denoising               65.0 (25.0)\n",
      "4.c Histogram               63.0 (26.0)\n",
      "4.d Skull                   75.0 (19.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Table 4 DICE WT\n",
    "import numpy as np\n",
    "metric = 'Dice'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "models = df_1_3['NN-Architecture (nn-Unet, UNETR)'].unique()\n",
    "epoch = 300\n",
    "# to save space in the paper and not write 0.44 and write 44 instead (only for Dice and Surface Dice)\n",
    "multiplier = 100\n",
    "\n",
    "\n",
    "def get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier):\n",
    "    \n",
    "    # mean\n",
    "    temp_series = (np.round(df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model ].groupby([ 'Preprocessing step'])[metric].mean(),3)*multiplier).round(0)\n",
    "    temp_series = temp_series.reindex(reindex_list)\n",
    "    temp_series.index = rename_list\n",
    "    temp_series_mean = temp_series\n",
    "\n",
    "    #std\n",
    "    temp_series = (np.round(df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model].groupby([ 'Preprocessing step'])[metric].std(),3)*multiplier).round(0)\n",
    "\n",
    "    temp_series = temp_series.reindex(reindex_list)\n",
    "    temp_series.index = rename_list\n",
    "    temp_series_std = temp_series\n",
    "\n",
    "    temp_mean_std = pd.concat([temp_series_mean, temp_series_std], axis=1)\n",
    "    temp_mean_std.columns = ['Mean', 'Std']\n",
    "    temp_mean_std['Mean (STD)'] = temp_mean_std.apply(lambda x: str(x['Mean']) + ' (' + str(x['Std']) + ')', axis=1)\n",
    "    return temp_mean_std['Mean (STD)'] \n",
    "\n",
    "print('DICE scores')\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print(data, model, metric)\n",
    "        print(get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier))\n",
    "        print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausdorff scores\n",
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Hausdorff\n",
      "1. Inter modality           31.0 (21.0)\n",
      "2. Resampling               15.0 (21.0)\n",
      "3. Atlas                    10.0 (11.0)\n",
      "4. Resampling to spacing    13.0 (20.0)\n",
      "4.a Bias                    14.0 (22.0)\n",
      "4.b Denoising               11.0 (16.0)\n",
      "4.c Histogram               13.0 (18.0)\n",
      "4.d Skull                   10.0 (14.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd nn_unet Hausdorff\n",
      "1. Inter modality             nan (nan)\n",
      "2. Resampling               26.0 (33.0)\n",
      "3. Atlas                    22.0 (27.0)\n",
      "4. Resampling to spacing    23.0 (34.0)\n",
      "4.a Bias                      nan (nan)\n",
      "4.b Denoising                 nan (nan)\n",
      "4.c Histogram                 nan (nan)\n",
      "4.d Skull                   15.0 (17.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "lgg nn_unet Hausdorff\n",
      "1. Inter modality           35.0 (36.0)\n",
      "2. Resampling               29.0 (32.0)\n",
      "3. Atlas                    27.0 (35.0)\n",
      "4. Resampling to spacing    38.0 (39.0)\n",
      "4.a Bias                    35.0 (36.0)\n",
      "4.b Denoising               35.0 (40.0)\n",
      "4.c Histogram               46.0 (41.0)\n",
      "4.d Skull                   23.0 (25.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "=======================NEW MODEL=======================\n",
      "gbm UNETR Hausdorff\n",
      "1. Inter modality           49.0 (24.0)\n",
      "2. Resampling               26.0 (30.0)\n",
      "3. Atlas                    18.0 (22.0)\n",
      "4. Resampling to spacing    16.0 (23.0)\n",
      "4.a Bias                    23.0 (28.0)\n",
      "4.b Denoising               26.0 (31.0)\n",
      "4.c Histogram               26.0 (31.0)\n",
      "4.d Skull                   12.0 (16.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd UNETR Hausdorff\n",
      "1. Inter modality             nan (nan)\n",
      "2. Resampling                 nan (nan)\n",
      "3. Atlas                      nan (nan)\n",
      "4. Resampling to spacing      nan (nan)\n",
      "4.a Bias                      nan (nan)\n",
      "4.b Denoising                 nan (nan)\n",
      "4.c Histogram               38.0 (36.0)\n",
      "4.d Skull                   20.0 (21.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "lgg UNETR Hausdorff\n",
      "1. Inter modality           35.0 (31.0)\n",
      "2. Resampling               36.0 (35.0)\n",
      "3. Atlas                    38.0 (34.0)\n",
      "4. Resampling to spacing    44.0 (36.0)\n",
      "4.a Bias                    41.0 (34.0)\n",
      "4.b Denoising               40.0 (37.0)\n",
      "4.c Histogram               46.0 (38.0)\n",
      "4.d Skull                   25.0 (28.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Appending Table  Hausdorff WT\n",
    "metric = 'Hausdorff'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "models = df_1_3['NN-Architecture (nn-Unet, UNETR)'].unique()\n",
    "\n",
    "#get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier=1)\n",
    "\n",
    "print('Hausdorff scores')\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print(data, model, metric)\n",
    "        print(get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier=1))\n",
    "        print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface Dice WT\n",
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Surface Dice 1mm\n",
      "1. Inter modality           27.0 (15.0)\n",
      "2. Resampling               65.0 (20.0)\n",
      "3. Atlas                    63.0 (20.0)\n",
      "4. Resampling to spacing    65.0 (20.0)\n",
      "4.a Bias                    60.0 (22.0)\n",
      "4.b Denoising               64.0 (21.0)\n",
      "4.c Histogram               63.0 (22.0)\n",
      "4.d Skull                   69.0 (20.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd nn_unet Surface Dice 1mm\n",
      "1. Inter modality           20.0 (14.0)\n",
      "2. Resampling               41.0 (18.0)\n",
      "3. Atlas                    44.0 (17.0)\n",
      "4. Resampling to spacing    43.0 (18.0)\n",
      "4.a Bias                    44.0 (19.0)\n",
      "4.b Denoising               42.0 (18.0)\n",
      "4.c Histogram               43.0 (18.0)\n",
      "4.d Skull                   45.0 (19.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "lgg nn_unet Surface Dice 1mm\n",
      "1. Inter modality           41.0 (24.0)\n",
      "2. Resampling               47.0 (24.0)\n",
      "3. Atlas                    46.0 (26.0)\n",
      "4. Resampling to spacing    46.0 (25.0)\n",
      "4.a Bias                    42.0 (25.0)\n",
      "4.b Denoising               44.0 (25.0)\n",
      "4.c Histogram               42.0 (24.0)\n",
      "4.d Skull                   52.0 (23.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "=======================NEW MODEL=======================\n",
      "gbm UNETR Surface Dice 1mm\n",
      "1. Inter modality           22.0 (12.0)\n",
      "2. Resampling               57.0 (21.0)\n",
      "3. Atlas                    56.0 (21.0)\n",
      "4. Resampling to spacing    59.0 (21.0)\n",
      "4.a Bias                    52.0 (21.0)\n",
      "4.b Denoising               60.0 (21.0)\n",
      "4.c Histogram               58.0 (21.0)\n",
      "4.d Skull                   64.0 (20.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd UNETR Surface Dice 1mm\n",
      "1. Inter modality           18.0 (13.0)\n",
      "2. Resampling               32.0 (16.0)\n",
      "3. Atlas                    34.0 (17.0)\n",
      "4. Resampling to spacing    34.0 (16.0)\n",
      "4.a Bias                    40.0 (17.0)\n",
      "4.b Denoising               37.0 (18.0)\n",
      "4.c Histogram               35.0 (16.0)\n",
      "4.d Skull                   38.0 (17.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "lgg UNETR Surface Dice 1mm\n",
      "1. Inter modality           33.0 (20.0)\n",
      "2. Resampling               35.0 (22.0)\n",
      "3. Atlas                    35.0 (22.0)\n",
      "4. Resampling to spacing    33.0 (20.0)\n",
      "4.a Bias                    31.0 (18.0)\n",
      "4.b Denoising               32.0 (20.0)\n",
      "4.c Histogram               32.0 (19.0)\n",
      "4.d Skull                   45.0 (21.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Appending Table  Surface Dice WT\n",
    "metric = 'Surface Dice 1mm'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "\n",
    "print('Surface Dice WT')\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print(data, model, metric)\n",
    "        print(get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier=100))\n",
    "        print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATISTICAL SIGNIFICANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_reg 13 ( 20 )  vs  31 ( 21 )\n",
      "Difference is significant, p-value  0.0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import ttost_ind, ttost_paired\n",
    "\n",
    "metric = 'Hausdorff'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "\n",
    "preproc_1 = \"4a_resamp\"\n",
    "for key in reindex_list:\n",
    "    preproc_2 = key\n",
    "    \n",
    "    if key != \"4a_resamp\":\n",
    "\n",
    "        data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "        data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "        \n",
    "        #assert if nan\n",
    "        assert data_1.isnull().sum() == 0\n",
    "        assert data_2.isnull().sum() == 0\n",
    "        \n",
    "        data_1 = np.array(data_1)\n",
    "        data_2 = np.array(data_2)\n",
    "        \n",
    "        ttost = ttost_paired(data_1, data_2, -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "        ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "\n",
    "        # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "        if (ttest_ < 0.05)&(ttost > 0.05):\n",
    "            print(preproc_2, (np.round(data_1.mean(),3)*1).round(0).astype(int), '(',\n",
    "              (np.round(data_1.std(),3)*1).round(0).astype(int), ')',\n",
    "              ' vs ',\\\n",
    "              (np.round(data_2.mean(),3)*1).round(0).astype(int), '(' ,\n",
    "              (np.round(data_2.std(),3)*1).round(0).astype(int),')')\n",
    "            print( \"Difference is significant, p-value \", np.round(ttest_,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2029292256.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 37\u001b[0;36m\u001b[0m\n\u001b[0;31m    if (ttest_ < 0.05)&(ttost > 0.05)::\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "metric = 'Dice'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print('==== new data ===')\n",
    "        fdr_pvalues_list = []\n",
    "        keys_list = []\n",
    "        preproc_1 = \"4a_resamp\"\n",
    "        for key in reindex_list:\n",
    "            preproc_2 = key\n",
    "            if key != \"4a_resamp\":\n",
    "\n",
    "                data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "                data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "                \n",
    "                #assert if nan\n",
    "                assert data_1.isnull().sum() == 0\n",
    "                assert data_2.isnull().sum() == 0\n",
    "                \n",
    "                data_1 = np.array(data_1)\n",
    "                data_2 = np.array(data_2)\n",
    "\n",
    "                ttost = ttost_paired(data_1, data_2, -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "                \n",
    "                ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "\n",
    "                fdr_pvalues_list.append(ttost)\n",
    "                keys_list.append(key)\n",
    "\n",
    "                # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "                if (ttest_ < 0.05)&(ttost > 0.05)::\n",
    "                    print(data, model, metric)\n",
    "                    print(preproc_1, preproc_2, (np.round(data_1.mean(),3)*100).round(0).astype(int), '(',\n",
    "                        (np.round(data_1.std(),3)*100).round(0).astype(int), ')',\n",
    "                        ' vs ',\\\n",
    "                        (np.round(data_2.mean(),3)*100).round(0).astype(int), '(' ,\n",
    "                        (np.round(data_2.std(),3)*100).round(0).astype(int),')')\n",
    "                    print( \"Difference is significant, p-value \", np.round(ttost,3))\n",
    "\n",
    "        fdr_correction_mask = ~fdrcorrection(fdr_pvalues_list, alpha=0.05, method='indep', is_sorted=False)[0]\n",
    "\n",
    "        print('FDR corrected p-values', np.take(list(keys_list),np.where(fdr_correction_mask==True)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================NEW MODEL=======================\n",
      "==== new data ===\n",
      "gbm nn_unet Hausdorff\n",
      "4a_resamp 1_reg 13 ( 20 )  vs  31 ( 21 )\n",
      "Difference is significant, p-value  0.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm nn_unet Hausdorff\n",
      "4a_resamp 3a_atlas 13 ( 20 )  vs  10 ( 11 )\n",
      "Difference is significant, p-value  0.081\n",
      "gbm nn_unet Hausdorff\n",
      "4a_resamp 5_ss_shared 13 ( 20 )  vs  10 ( 14 )\n",
      "Difference is significant, p-value  0.055\n",
      "FDR corrected p-values ['1_reg' '3a_atlas' '5_ss_shared']\n",
      "==== new data ===\n",
      "bgpd nn_unet Hausdorff\n",
      "4a_resamp 5_ss_shared 23 ( 34 )  vs  15 ( 17 )\n",
      "Difference is significant, p-value  0.132\n",
      "FDR corrected p-values ['1_reg' '4b_n4' '4d_susan' '6_hist' '5_ss_shared']\n",
      "==== new data ===\n",
      "lgg nn_unet Hausdorff\n",
      "4a_resamp 2a_interp 38 ( 39 )  vs  29 ( 32 )\n",
      "Difference is significant, p-value  0.085\n",
      "lgg nn_unet Hausdorff\n",
      "4a_resamp 3a_atlas 38 ( 39 )  vs  27 ( 35 )\n",
      "Difference is significant, p-value  0.109\n",
      "lgg nn_unet Hausdorff\n",
      "4a_resamp 5_ss_shared 38 ( 39 )  vs  23 ( 24 )\n",
      "Difference is significant, p-value  0.142\n",
      "FDR corrected p-values ['2a_interp' '3a_atlas' '6_hist' '5_ss_shared']\n",
      "=======================NEW MODEL=======================\n",
      "==== new data ===\n",
      "gbm UNETR Hausdorff\n",
      "4a_resamp 1_reg 16 ( 23 )  vs  49 ( 24 )\n",
      "Difference is significant, p-value  0.143\n",
      "gbm UNETR Hausdorff\n",
      "4a_resamp 2a_interp 16 ( 23 )  vs  26 ( 30 )\n",
      "Difference is significant, p-value  0.116\n",
      "gbm UNETR Hausdorff\n",
      "4a_resamp 4b_n4 16 ( 23 )  vs  23 ( 28 )\n",
      "Difference is significant, p-value  0.071\n",
      "gbm UNETR Hausdorff\n",
      "4a_resamp 4d_susan 16 ( 23 )  vs  26 ( 31 )\n",
      "Difference is significant, p-value  0.118\n",
      "gbm UNETR Hausdorff\n",
      "4a_resamp 6_hist 16 ( 23 )  vs  26 ( 31 )\n",
      "Difference is significant, p-value  0.115\n",
      "gbm UNETR Hausdorff\n",
      "4a_resamp 5_ss_shared 16 ( 23 )  vs  12 ( 16 )\n",
      "Difference is significant, p-value  0.075\n",
      "FDR corrected p-values ['1_reg' '2a_interp' '3a_atlas' '4b_n4' '4d_susan' '6_hist' '5_ss_shared']\n",
      "==== new data ===\n",
      "FDR corrected p-values ['1_reg' '2a_interp' '3a_atlas' '4b_n4' '4d_susan' '6_hist' '5_ss_shared']\n",
      "==== new data ===\n",
      "lgg UNETR Hausdorff\n",
      "4a_resamp 1_reg 44 ( 36 )  vs  35 ( 31 )\n",
      "Difference is significant, p-value  0.091\n",
      "lgg UNETR Hausdorff\n",
      "4a_resamp 2a_interp 44 ( 36 )  vs  36 ( 35 )\n",
      "Difference is significant, p-value  0.059\n",
      "lgg UNETR Hausdorff\n",
      "4a_resamp 5_ss_shared 44 ( 36 )  vs  25 ( 28 )\n",
      "Difference is significant, p-value  0.141\n",
      "FDR corrected p-values ['1_reg' '2a_interp' '3a_atlas' '5_ss_shared']\n"
     ]
    }
   ],
   "source": [
    "metric = 'Hausdorff'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print('==== new data ===')\n",
    "        fdr_pvalues_list = []\n",
    "        keys_list = []\n",
    "        preproc_1 = \"4a_resamp\"\n",
    "\n",
    "        for key in reindex_list:\n",
    "            preproc_2 = key\n",
    "\n",
    "            if key != \"4a_resamp\":\n",
    "\n",
    "                data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "                data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "                \n",
    "                #assert if nan\n",
    "                assert data_1.isnull().sum() == 0\n",
    "                assert data_2.isnull().sum() == 0\n",
    "                \n",
    "                data_1 = np.array(data_1)\n",
    "                data_2 = np.array(data_2)\n",
    "\n",
    "                ttost = ttost_paired(data_1, data_2, -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "                ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "\n",
    "                fdr_pvalues_list.append(ttost)\n",
    "                keys_list.append(key)\n",
    "\n",
    "                # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "                if (ttest_ < 0.05)&(ttost > 0.05)::\n",
    "                    print(data, model, metric)\n",
    "                    print(preproc_1,preproc_2, (np.round(data_1.mean(),3)*1).round(0).astype(int), '(',\n",
    "                      (np.round(data_1.std(),3)*1).round(0).astype(int), ')',\n",
    "                      ' vs ',\\\n",
    "                      (np.round(data_2.mean(),3)*1).round(0).astype(int), '(' ,\n",
    "                      (np.round(data_2.std(),3)*1).round(0).astype(int),')')\n",
    "                    print( \"Difference is significant, p-value \", np.round(ttost,3))\n",
    "\n",
    "        fdr_correction_mask = ~fdrcorrection(fdr_pvalues_list, alpha=0.05, method='indep', is_sorted=False)[0]\n",
    "\n",
    "        print('FDR corrected p-values', np.take(list(keys_list),np.where(fdr_correction_mask==True)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================NEW MODEL=======================\n",
      "==== new data ===\n",
      "gbm nn_unet Surface Dice 1mm\n",
      "1_reg 65 ( 20 )  vs  27 ( 15 )\n",
      "Difference is significant, p-value  0.0\n",
      "gbm nn_unet Surface Dice 1mm\n",
      "4b_n4 65 ( 20 )  vs  60 ( 22 )\n",
      "Difference is significant, p-value  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDR corrected p-values ['1_reg' '4b_n4']\n",
      "==== new data ===\n",
      "bgpd nn_unet Surface Dice 1mm\n",
      "1_reg 43 ( 18 )  vs  20 ( 14 )\n",
      "Difference is significant, p-value  0.0\n",
      "FDR corrected p-values ['1_reg']\n",
      "==== new data ===\n",
      "lgg nn_unet Surface Dice 1mm\n",
      "5_ss_shared 46 ( 25 )  vs  52 ( 23 )\n",
      "Difference is significant, p-value  0.004\n",
      "FDR corrected p-values ['5_ss_shared']\n",
      "=======================NEW MODEL=======================\n",
      "==== new data ===\n",
      "gbm UNETR Surface Dice 1mm\n",
      "1_reg 59 ( 21 )  vs  22 ( 12 )\n",
      "Difference is significant, p-value  0.0\n",
      "gbm UNETR Surface Dice 1mm\n",
      "4b_n4 59 ( 21 )  vs  52 ( 21 )\n",
      "Difference is significant, p-value  0.0\n",
      "gbm UNETR Surface Dice 1mm\n",
      "5_ss_shared 59 ( 21 )  vs  64 ( 20 )\n",
      "Difference is significant, p-value  0.011\n",
      "FDR corrected p-values ['1_reg' '4b_n4' '5_ss_shared']\n",
      "==== new data ===\n",
      "bgpd UNETR Surface Dice 1mm\n",
      "1_reg 34 ( 16 )  vs  18 ( 13 )\n",
      "Difference is significant, p-value  0.0\n",
      "bgpd UNETR Surface Dice 1mm\n",
      "4b_n4 34 ( 16 )  vs  40 ( 17 )\n",
      "Difference is significant, p-value  0.0\n",
      "bgpd UNETR Surface Dice 1mm\n",
      "5_ss_shared 34 ( 16 )  vs  38 ( 17 )\n",
      "Difference is significant, p-value  0.0\n",
      "FDR corrected p-values ['1_reg' '4b_n4' '5_ss_shared']\n",
      "==== new data ===\n",
      "lgg UNETR Surface Dice 1mm\n",
      "5_ss_shared 33 ( 19 )  vs  45 ( 21 )\n",
      "Difference is significant, p-value  0.0\n",
      "FDR corrected p-values ['5_ss_shared']\n"
     ]
    }
   ],
   "source": [
    "metric = 'Surface Dice 1mm'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print('==== new data ===')\n",
    "        fdr_pvalues_list = []\n",
    "        keys_list = []\n",
    "        preproc_1 = \"4a_resamp\"\n",
    "        for key in reindex_list:\n",
    "            preproc_2 = key\n",
    "\n",
    "            if key != \"4a_resamp\":\n",
    "\n",
    "                data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "                data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "                \n",
    "                #assert if nan\n",
    "                assert data_1.isnull().sum() == 0\n",
    "                assert data_2.isnull().sum() == 0\n",
    "                \n",
    "                data_1 = np.array(data_1)\n",
    "                data_2 = np.array(data_2)\n",
    "\n",
    "                ttost = ttost_paired(data_1, data_2, -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "                ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "                \n",
    "                fdr_pvalues_list.append(ttost)\n",
    "                keys_list.append(key)\n",
    "\n",
    "                # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "                if (ttest_ < 0.05)&(ttost > 0.05)::\n",
    "                    print(data, model, metric)\n",
    "                    print(preproc_2, (np.round(data_1.mean(),3)*100).round(0).astype(int), '(',\n",
    "                      (np.round(data_1.std(),3)*100).round(0).astype(int), ')',\n",
    "                      ' vs ',\\\n",
    "                      (np.round(data_2.mean(),3)*100).round(0).astype(int), '(' ,\n",
    "                      (np.round(data_2.std(),3)*100).round(0).astype(int),')')\n",
    "                    print( \"Difference is significant, p-value \", np.round(ttest_,3))\n",
    "        \n",
    "        fdr_correction_mask = ~fdrcorrection(fdr_pvalues_list, alpha=0.05, method='indep', is_sorted=False)[0]\n",
    "\n",
    "        print('FDR corrected p-values', np.take(list(keys_list),np.where(fdr_correction_mask==True)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
