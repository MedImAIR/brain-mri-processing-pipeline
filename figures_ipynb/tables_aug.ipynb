{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_1_3 = pd.read_csv('results/6_augmentation.tsv',  sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICE scores\n",
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Dice\n",
      "1. Inter modality             nan (nan)\n",
      "2. Resampling                 nan (nan)\n",
      "3. Atlas                      nan (nan)\n",
      "4. Resampling to spacing    84.0 (12.0)\n",
      "4.a Bias                      nan (nan)\n",
      "4.b Denoising                 nan (nan)\n",
      "4.c Histogram                 nan (nan)\n",
      "4.d Skull                   87.0 (10.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n",
      "bgpd nn_unet Dice\n",
      "1. Inter modality             nan (nan)\n",
      "2. Resampling                 nan (nan)\n",
      "3. Atlas                      nan (nan)\n",
      "4. Resampling to spacing    73.0 (20.0)\n",
      "4.a Bias                      nan (nan)\n",
      "4.b Denoising                 nan (nan)\n",
      "4.c Histogram                 nan (nan)\n",
      "4.d Skull                   77.0 (14.0)\n",
      "Name: Mean (STD), dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Table 4 DICE WT\n",
    "models = df_1_3['NN-Architecture (nn-Unet, UNETR)'].unique()\n",
    "metric = 'Dice'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "# to save space in the paper and not write 0.44 and write 44 instead (only for Dice and Surface Dice)\n",
    "multiplier = 100\n",
    "reindex_list = ['1_reg', '2a_interp', '3a_atlas', '4a_resamp', '4b_n4', '4d_susan','6_hist','5_ss_shared']\n",
    "rename_list = ['1. Inter modality', '2. Resampling', '3. Atlas', '4. Resampling to spacing', '4.a Bias', '4.b Denoising', '4.c Histogram', '4.d Skull']\n",
    "\n",
    "\n",
    "def get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier):\n",
    "    \n",
    "    # mean\n",
    "    temp_series = (np.round(df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model ].groupby([ 'Preprocessing step'])[metric].mean(),3)*multiplier).round(0)\n",
    "    temp_series = temp_series.reindex(reindex_list)\n",
    "    temp_series.index = rename_list\n",
    "    temp_series_mean = temp_series\n",
    "\n",
    "    #std\n",
    "    temp_series = (np.round(df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model].groupby([ 'Preprocessing step'])[metric].std(),3)*multiplier).round(0)\n",
    "\n",
    "    temp_series = temp_series.reindex(reindex_list)\n",
    "    temp_series.index = rename_list\n",
    "    temp_series_std = temp_series\n",
    "\n",
    "    temp_mean_std = pd.concat([temp_series_mean, temp_series_std], axis=1)\n",
    "    temp_mean_std.columns = ['Mean', 'Std']\n",
    "    temp_mean_std['Mean (STD)'] = temp_mean_std.apply(lambda x: str(x['Mean']) + ' (' + str(x['Std']) + ')', axis=1)\n",
    "    return temp_mean_std['Mean (STD)'] \n",
    "\n",
    "print('DICE scores')\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        print(data, model, metric)\n",
    "        print(get_column_from_pivot_table(df_1_3, metric, data, label, model, epoch, multiplier))\n",
    "        print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to check where to put rows on the statistical significance:\n",
    "\n",
    "def dropna_intersection(data_1: pd.Series, data_2: pd.Series):\n",
    "    data_1 = data_1.reset_index(drop=True)\n",
    "    data_2 = data_2.reset_index(drop=True)\n",
    "\n",
    "    data_1 = data_1.dropna()\n",
    "    data_2 = data_2.dropna()\n",
    "\n",
    "    data_1 = data_1[data_1.index.isin(data_2.index)]\n",
    "    data_2 = data_2[data_2.index.isin(data_1.index)]\n",
    "    \n",
    "    return data_1, data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Dice\n",
      "5_ss_shared 84 ( 12 )  vs  87 ( 10 )\n",
      "Difference is significant, p-value  0.106\n",
      "\n",
      "bgpd nn_unet Dice\n",
      "5_ss_shared 73 ( 20 )  vs  77 ( 14 )\n",
      "Difference is significant, p-value  0.102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import ttost_ind, ttost_paired\n",
    "\n",
    "metric = 'Dice'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        preproc_1 = \"4a_resamp\"\n",
    "        for key in reindex_list:\n",
    "            preproc_2 = key\n",
    "\n",
    "            if key != \"4a_resamp\":\n",
    "\n",
    "                data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "                data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "                data_1, data_2 = dropna_intersection(data_1, data_2)\n",
    "\n",
    "                ttost = ttost_paired(np.array(data_1), np.array(data_2), -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "                ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "                                \n",
    "                #assert isna\n",
    "                assert data_1.isnull().sum() == 0\n",
    "                assert data_2.isnull().sum() == 0\n",
    "\n",
    "                # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "                if (ttest_ < 0.05)&(ttost > 0.05):\n",
    "                    print(data, model, metric)\n",
    "                    print(preproc_2, (np.round(data_1.mean(),3)*100).round(0).astype(int), '(',\n",
    "                      (np.round(data_1.std(),3)*100).round(0).astype(int), ')',\n",
    "                      ' vs ',\\\n",
    "                      (np.round(data_2.mean(),3)*100).round(0).astype(int), '(' ,\n",
    "                      (np.round(data_2.std(),3)*100).round(0).astype(int),')')\n",
    "                    print( \"Difference is significant, p-value \", np.round(ttost,3))\n",
    "                    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Dice\n",
      "5_ss_shared 84 ( 12 )  vs  87 ( 10 )\n",
      "Difference is significant, p-value  0.0\n",
      "\n",
      "bgpd nn_unet Dice\n",
      "5_ss_shared 73 ( 20 )  vs  77 ( 14 )\n",
      "Difference is significant, p-value  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = 'Dice'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        preproc_1 = \"4a_resamp\"\n",
    "        for key in reindex_list:\n",
    "            preproc_2 = key\n",
    "\n",
    "            if key != \"4a_resamp\":\n",
    "\n",
    "                data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "                data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "                data_1, data_2 = dropna_intersection(data_1, data_2)\n",
    "\n",
    "                ttost = ttost_paired(np.array(data_1), np.array(data_2), -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "                ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "                                \n",
    "                #assert isna\n",
    "                assert data_1.isnull().sum() == 0\n",
    "                assert data_2.isnull().sum() == 0\n",
    "\n",
    "                # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "                if (ttest_ < 0.05)&(ttost > 0.05):\n",
    "                    print(data, model, metric)\n",
    "                    print(preproc_2, (np.round(data_1.mean(),3)*100).round(0).astype(int), '(',\n",
    "                      (np.round(data_1.std(),3)*100).round(0).astype(int), ')',\n",
    "                      ' vs ',\\\n",
    "                      (np.round(data_2.mean(),3)*100).round(0).astype(int), '(' ,\n",
    "                      (np.round(data_2.std(),3)*100).round(0).astype(int),')')\n",
    "                    print( \"Difference is significant, p-value \", np.round(ttest_,3))\n",
    "                    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================NEW MODEL=======================\n",
      "gbm nn_unet Surface Dice 1mm\n",
      "5_ss_shared 64 ( 21 )  vs  70 ( 20 )\n",
      "Difference is significant, p-value  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = 'Surface Dice 1mm'\n",
    "data = 'gbm'\n",
    "label = 'WT'\n",
    "model = 'nn_unet'\n",
    "epoch = 300\n",
    "\n",
    "for model in models:\n",
    "    print('=======================NEW MODEL=======================')\n",
    "    for data in df_1_3.Dataset.unique():\n",
    "        preproc_1 = \"4a_resamp\"\n",
    "        for key in reindex_list:\n",
    "            preproc_2 = key\n",
    "\n",
    "            if key != \"4a_resamp\":\n",
    "\n",
    "                data_1 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_1][metric]\n",
    "                data_2 = df_1_3[df_1_3.Dataset==data][df_1_3.Epoch==epoch][df_1_3['Label (WT, ET, TC, GTV)']==label][df_1_3['NN-Architecture (nn-Unet, UNETR)']==model][df_1_3['Preprocessing step']==preproc_2][metric]\n",
    "                data_1, data_2 = dropna_intersection(data_1, data_2)\n",
    "                \n",
    "                #assert isna\n",
    "                assert data_1.isnull().sum() == 0\n",
    "                assert data_2.isnull().sum() == 0\n",
    "\n",
    "                ttost = ttost_ind(data_1, data_2, -data_2.std()/4, data_2.std()/4)[0]/7\n",
    "                ttest_ = scipy.stats.wilcoxon(data_1, data_2,  alternative='two-sided')[1]*7\n",
    "\n",
    "                # print(\"If more than 0.05\", ttost > 0.05, np.round(ttost,3))\n",
    "                if (ttest_ < 0.05)&(ttost > 0.05):\n",
    "                    print(data, model, metric)\n",
    "                    print(preproc_2, (np.round(data_1.mean(),3)*100).round(0).astype(int), '(',\n",
    "                      (np.round(data_1.std(),3)*100).round(0).astype(int), ')',\n",
    "                      ' vs ',\\\n",
    "                      (np.round(data_2.mean(),3)*100).round(0).astype(int), '(' ,\n",
    "                      (np.round(data_2.std(),3)*100).round(0).astype(int),')')\n",
    "                    print( \"Difference is significant, p-value \", np.round(ttest_,3))\n",
    "                    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
